{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f292f216-448c-4304-8224-0cbf9a2022c9",
   "metadata": {},
   "source": [
    "# SORA with Azure AI Foundry\n",
    "> https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/video-generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efafceee-6fbf-401d-bae8-824767771471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "029dd448-1591-4548-9e75-281d717a3062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd844f89-064a-4146-97b0-8bff137f02f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 30-May-2025 09:19:09\n"
     ]
    }
   ],
   "source": [
    "print(f\"Today is {datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57c18b14-9a8a-4c60-87e6-1b557a964a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "SORA_DIR = \"videos\"\n",
    "\n",
    "os.makedirs(SORA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5143ddfb-603d-4cef-ad78-fefa7ed70c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"azure.env\")\n",
    "\n",
    "endpoint = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "api_key = os.environ['AZURE_OPENAI_API_KEY']\n",
    "\n",
    "model = \"sora\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20797e2-8ca9-4f63-954f-2bfa1723b3be",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9688580-4ed4-4e58-b162-ca62613b5e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sora(prompt, width=480, height=480, n_seconds=5, n_variants=1):\n",
    "    \"\"\"\n",
    "    Generates a video based on the given prompt using the SORA model.\n",
    "\n",
    "    Parameters:\n",
    "    prompt (str): The text prompt to generate the video.\n",
    "    width (int): The width of the video. Supported values are 480, 854, 720, 1080, and 1920.\n",
    "    height (int): The height of the video. Supported values are 480, 854, 720, 1080, and 1920.\n",
    "    n_seconds (int): The duration of the video in seconds. Must be between 1 and 20 seconds.\n",
    "    n_variants (int): The number of video variants to generate.\n",
    "    \n",
    "    Returns:\n",
    "    str: The filename of the generated video.\n",
    "\n",
    "    Raises:\n",
    "    Exception: If the video generation job fails or no generations are found.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    api_version = 'preview'\n",
    "    headers = {\"api-key\": api_key, \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    idx = datetime.datetime.today().strftime('%d%b%Y_%H%M%S')\n",
    "    output_filename = os.path.join(SORA_DIR, f\"sora_{idx}.mp4\")\n",
    "\n",
    "    # 1. Create a video generation job\n",
    "    create_url = f\"{endpoint}/openai/v1/video/generations/jobs?api-version={api_version}\"\n",
    "    body = {\n",
    "        \"prompt\": prompt,\n",
    "        \"width\": width,  # 480x480, 480x854, 854x480, 720x720, 720x1280, 1280x720, 1080x1080, 1080x1920, 1920x1080.\n",
    "        \"height\": height,  # 480x480, 480x854, 854x480, 720x720, 720x1280, 1280x720, 1080x1080, 1080x1920, 1920x1080.\n",
    "        \"n_seconds\": n_seconds,  # between 1 and 20 seconds\n",
    "        \"n_variants\": n_variants,\n",
    "        \"model\": model,  # SORA model\n",
    "    }\n",
    "    response = requests.post(create_url, headers=headers, json=body)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    now = datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')\n",
    "    print(f\"{now} Full response JSON:\", response.json())\n",
    "    print()\n",
    "    \n",
    "    job_id = response.json()[\"id\"]\n",
    "    now = datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')\n",
    "    print(f\"{now} Job created: {job_id}\")\n",
    "\n",
    "    # 2. Poll for job status\n",
    "    status_url = f\"{endpoint}/openai/v1/video/generations/jobs/{job_id}?api-version={api_version}\"\n",
    "    status = None\n",
    "\n",
    "    while status not in (\"succeeded\", \"failed\", \"cancelled\"):\n",
    "        time.sleep(5)  # Wait before polling again\n",
    "        status_response = requests.get(status_url, headers=headers).json()\n",
    "        status = status_response.get(\"status\")\n",
    "        now = datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')\n",
    "        print(f\"{now} Job status: {status}\")\n",
    "\n",
    "    # 3. Retrieve generated video\n",
    "    if status == \"succeeded\":\n",
    "        generations = status_response.get(\"generations\", [])\n",
    "        \n",
    "        if generations:\n",
    "            now = datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')\n",
    "            print(f\"\\n{now} ✅ Done. Video generation succeeded.\")\n",
    "            generation_id = generations[0].get(\"id\")\n",
    "            video_url = f\"{endpoint}/openai/v1/video/generations/{generation_id}/content/video?api-version={api_version}\"\n",
    "            video_response = requests.get(video_url, headers=headers)\n",
    "            \n",
    "            if video_response.ok:\n",
    "                # Downloading the video\n",
    "                with open(output_filename, \"wb\") as file:\n",
    "                    file.write(video_response.content)\n",
    "                    print(f\"\\nSORA Generated video saved: '{output_filename}'\")\n",
    "\n",
    "                elapsed = time.time() - start\n",
    "                minutes, seconds = divmod(elapsed, 60)\n",
    "                print(f\"Done in {minutes:.0f} minutes and {seconds:.0f} seconds\")\n",
    "                \n",
    "                return output_filename\n",
    "        else:\n",
    "            raise Exception(\"Error. No generations found in job result.\")\n",
    "    else:\n",
    "        raise Exception(f\"Error. Job did not succeed. Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b865643f-526e-409c-8ba8-9d8ee7a8ea46",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "950e76ca-3c62-45cb-bfbe-de46f8acf1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30-May-2025 09:19:09 Full response JSON: {'object': 'video.generation.job', 'id': 'task_01jwg7sxhcf2wsj89eb97sxen5', 'status': 'queued', 'created_at': 1748596749, 'finished_at': None, 'expires_at': None, 'generations': [], 'prompt': 'Young boy and his father playing together in the ocean on the beach', 'model': 'sora', 'n_variants': 1, 'n_seconds': 5, 'height': 480, 'width': 480, 'failure_reason': None}\n",
      "\n",
      "30-May-2025 09:19:09 Job created: task_01jwg7sxhcf2wsj89eb97sxen5\n",
      "30-May-2025 09:19:15 Job status: running\n",
      "30-May-2025 09:19:20 Job status: running\n",
      "30-May-2025 09:19:26 Job status: processing\n",
      "30-May-2025 09:19:31 Job status: succeeded\n",
      "\n",
      "30-May-2025 09:19:31 ✅ Done. Video generation succeeded.\n",
      "\n",
      "SORA Generated video saved: 'videos/sora_30May2025_091909.mp4'\n",
      "Done in 0 minutes and 26 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Young boy and his father playing together in the ocean on the beach\"\n",
    "\n",
    "generated_video = sora(prompt, width=480, height=480, n_seconds=5, n_variants=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02cfc386-2ac8-4ce8-ad8f-b490999ff9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/sora_30May2025_091909.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(generated_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16a869c9-2a21-4141-9167-b504e28f9c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30-May-2025 09:19:35 Full response JSON: {'object': 'video.generation.job', 'id': 'task_01jwg7tpgzf7esfthsn3011ej1', 'status': 'queued', 'created_at': 1748596775, 'finished_at': None, 'expires_at': None, 'generations': [], 'prompt': \"An image of a realistic cloud that spells 'SORA with birds around'\", 'model': 'sora', 'n_variants': 1, 'n_seconds': 5, 'height': 480, 'width': 480, 'failure_reason': None}\n",
      "\n",
      "30-May-2025 09:19:35 Job created: task_01jwg7tpgzf7esfthsn3011ej1\n",
      "30-May-2025 09:19:40 Job status: queued\n",
      "30-May-2025 09:19:46 Job status: running\n",
      "30-May-2025 09:19:51 Job status: succeeded\n",
      "\n",
      "30-May-2025 09:19:51 ✅ Done. Video generation succeeded.\n",
      "\n",
      "SORA Generated video saved: 'videos/sora_30May2025_091935.mp4'\n",
      "Done in 0 minutes and 19 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = \"An image of a realistic cloud that spells 'SORA with birds around'\"\n",
    "\n",
    "generated_video = sora(prompt, width=480, height=480, n_seconds=5, n_variants=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd8a2d32-1a32-45f4-86e4-41379c79e6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/sora_30May2025_091935.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(generated_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d6fdc78-666a-48f1-bc34-6d205853557f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30-May-2025 09:19:54 Full response JSON: {'object': 'video.generation.job', 'id': 'task_01jwg7v8saesabp2bt89abhts0', 'status': 'queued', 'created_at': 1748596794, 'finished_at': None, 'expires_at': None, 'generations': [], 'prompt': 'Several giant wooly mammoths approach treading through a snowy meadow, their long wooly fur lightly blows in the wind as they walk, snow covered trees and dramatic snow capped mountains in the distance, mid afternoon light with wispy clouds and a sun high in the distance creates a warm glow, the low camera view is stunning capturing the large furry mammal with beautiful photography, depth of field.', 'model': 'sora', 'n_variants': 1, 'n_seconds': 5, 'height': 480, 'width': 480, 'failure_reason': None}\n",
      "\n",
      "30-May-2025 09:19:54 Job created: task_01jwg7v8saesabp2bt89abhts0\n",
      "30-May-2025 09:19:59 Job status: preprocessing\n",
      "30-May-2025 09:20:05 Job status: running\n",
      "30-May-2025 09:20:10 Job status: succeeded\n",
      "\n",
      "30-May-2025 09:20:10 ✅ Done. Video generation succeeded.\n",
      "\n",
      "SORA Generated video saved: 'videos/sora_30May2025_091953.mp4'\n",
      "Done in 0 minutes and 19 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Several giant wooly mammoths approach treading through a snowy meadow, their long wooly fur lightly blows in the wind as they walk, snow covered trees and dramatic snow capped mountains in the distance, mid afternoon light with wispy clouds and a sun high in the distance creates a warm glow, the low camera view is stunning capturing the large furry mammal with beautiful photography, depth of field.\"\n",
    "\n",
    "generated_video = sora(prompt, width=480, height=480, n_seconds=5, n_variants=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ee2ddc6-e664-49d5-93e3-388ba3febbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/sora_30May2025_091953.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(generated_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66572c10-eaef-4a8a-949b-1ff08c0fe5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30-May-2025 09:20:13 Full response JSON: {'object': 'video.generation.job', 'id': 'task_01jwg7vv6nfnq885kab1z65yww', 'status': 'queued', 'created_at': 1748596813, 'finished_at': None, 'expires_at': None, 'generations': [], 'prompt': 'Paris submerged like Atlantis. Fish, whales, sea turtles and sharks swim through the streets of Paris.', 'model': 'sora', 'n_variants': 1, 'n_seconds': 5, 'height': 480, 'width': 480, 'failure_reason': None}\n",
      "\n",
      "30-May-2025 09:20:13 Job created: task_01jwg7vv6nfnq885kab1z65yww\n",
      "30-May-2025 09:20:18 Job status: preprocessing\n",
      "30-May-2025 09:20:23 Job status: running\n",
      "30-May-2025 09:20:29 Job status: succeeded\n",
      "\n",
      "30-May-2025 09:20:29 ✅ Done. Video generation succeeded.\n",
      "\n",
      "SORA Generated video saved: 'videos/sora_30May2025_092012.mp4'\n",
      "Done in 0 minutes and 20 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Paris submerged like Atlantis. Fish, whales, sea turtles and sharks swim through the streets of Paris.\"\n",
    "\n",
    "generated_video = sora(prompt, width=480, height=480, n_seconds=5, n_variants=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "369993b4-8752-4fdf-9161-38a0da817313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/sora_30May2025_092012.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(generated_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "206e58c4-cd79-4181-82d3-b5bf770036e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30-May-2025 09:20:32 Full response JSON: {'object': 'video.generation.job', 'id': 'task_01jwg7webwe8sb1rhd94wq5gj4', 'status': 'queued', 'created_at': 1748596832, 'finished_at': None, 'expires_at': None, 'generations': [], 'prompt': 'A instructional cooking session for homemade gnocchi hosted by a grandmother social media influencer set in a rustic Tuscan country kitchen with cinematic lighting.', 'model': 'sora', 'n_variants': 1, 'n_seconds': 5, 'height': 480, 'width': 480, 'failure_reason': None}\n",
      "\n",
      "30-May-2025 09:20:32 Job created: task_01jwg7webwe8sb1rhd94wq5gj4\n",
      "30-May-2025 09:20:38 Job status: preprocessing\n",
      "30-May-2025 09:20:43 Job status: running\n",
      "30-May-2025 09:20:48 Job status: processing\n",
      "30-May-2025 09:20:54 Job status: succeeded\n",
      "\n",
      "30-May-2025 09:20:54 ✅ Done. Video generation succeeded.\n",
      "\n",
      "SORA Generated video saved: 'videos/sora_30May2025_092032.mp4'\n",
      "Done in 0 minutes and 24 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = \"A instructional cooking session for homemade gnocchi hosted by a grandmother social media influencer set in a rustic Tuscan country kitchen with cinematic lighting.\"\n",
    "\n",
    "generated_video = sora(prompt, width=480, height=480, n_seconds=5, n_variants=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4484f16c-f315-4818-b5ae-9edf70a490e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/sora_30May2025_092032.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(generated_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ac98e4-b5db-4a29-9e16-05361a01c6f2",
   "metadata": {},
   "source": [
    "## Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c48bde55-aabd-4af4-96b6-0eacf3a76571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 15M\n",
      "-rwxrwxrwx 1 root root 4.7M May 30 09:19 sora_30May2025_091909.mp4\n",
      "-rwxrwxrwx 1 root root 2.1M May 30 09:19 sora_30May2025_091935.mp4\n",
      "-rwxrwxrwx 1 root root 2.1M May 30 09:20 sora_30May2025_091953.mp4\n",
      "-rwxrwxrwx 1 root root 3.0M May 30 09:20 sora_30May2025_092012.mp4\n",
      "-rwxrwxrwx 1 root root 3.0M May 30 09:20 sora_30May2025_092032.mp4\n"
     ]
    }
   ],
   "source": [
    "!ls $SORA_DIR -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b40f5c-2919-4bbd-b783-160c17ec228a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
