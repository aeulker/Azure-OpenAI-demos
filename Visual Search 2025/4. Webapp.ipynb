{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Search demo\n",
    "\n",
    "<img src=\"logo.png\" width=350>\n",
    "\n",
    "## 4. Webapp\n",
    "Build a visual search web app using Azure AI Vision and Azure AI Search by embedding images and prompts into vectors, indexing them, and retrieving similar results via Gradio UI.\n",
    "\n",
    "## Steps\n",
    "- Generate vector embeddings for images and text using Azure AI.\n",
    "- Create and configure an Azure AI Search index.\n",
    "- Upload images to Azure Blob Storage.\n",
    "- Index the image vectors into Azure AI Search.\n",
    "- Build a Gradio web app for prompt-based and image-based search.\n",
    "- Launch the app with a tabbed interface for both search modes and image generation.\n",
    "\n",
    "## Visual search with vector embeddings\n",
    "Vector embeddings are a way of representing content such as text or images as vectors of real numbers in a high-dimensional space. These embeddings are often learned from large amounts of textual and visual data using machine learning algorithms like neural networks. Each dimension of the vector corresponds to a different feature or attribute of the content, such as its semantic meaning, syntactic role, or context in which it commonly appears. By representing content as vectors, we can perform mathematical operations on them to compare their similarity or use them as inputs to machine learning models.\n",
    "\n",
    "## Business applications\n",
    "- Digital asset management: Image retrieval can be used to manage large collections of digital images, such as in museums, archives, or online galleries. Users can search for images based on visual features and retrieve the images that match their criteria.\n",
    "- Medical image retrieval: Image retrieval can be used in medical imaging to search for images based on their diagnostic features or disease patterns. This can help doctors or researchers to identify similar cases or track disease progression.\n",
    "- Security and surveillance: Image retrieval can be used in security and surveillance systems to search for images based on specific features or patterns, such as in, people & object tracking, or threat detection.\n",
    "- Forensic image retrieval: Image retrieval can be used in forensic investigations to search for images based on their visual content or metadata, such as in cases of cyber-crime.\n",
    "- E-commerce: Image retrieval can be used in online shopping applications to search for similar products based on their features or descriptions or provide recommendations based on previous purchases.\n",
    "- Fashion and design: Image retrieval can be used in fashion and design to search for images based on their visual features, such as color, pattern, or texture. This can help designers or retailers to identify similar products or trends.\n",
    "\n",
    "## Images\n",
    "In this notebook we took some samples fashion images are taken from this link:<br>\n",
    "https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"screenshot.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "import gradio as gr\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "from azurevisualsearch import get_image_embedding, get_index_stats, text_embedding\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "from dotenv import load_dotenv\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from typing import List, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 2025-07-30\n"
     ]
    }
   ],
   "source": [
    "print(f\"Today is {datetime.datetime.now().strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Azure AI Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"azure.env\")\n",
    "\n",
    "# Azure AI Vision\n",
    "azure_vision_key = os.getenv(\"azure_vision_key\")\n",
    "azure_vision_endpoint = os.getenv(\"azure_vision_endpoint\")\n",
    "api_version = \"2024-02-01\"\n",
    "model_version = \"2023-04-15\"\n",
    "\n",
    "# Azure AI Search\n",
    "azure_search_key = os.getenv(\"azure_search_key\")\n",
    "azure_search_endpoint = os.getenv(\"azure_search_endpoint\")\n",
    "index_name = \"fashion-demo-2025\"\n",
    "\n",
    "# Azure storage account\n",
    "blob_connection_string = os.getenv(\"blob_connection_string\")\n",
    "container_name = os.getenv(\"container_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_DIR = \"images\"\n",
    "\n",
    "COMPOSE_DIR = f\"{IMAGES_DIR}/compose_images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Blob storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL of the first blob: https://azurestorageaccountsr.blob.core.windows.net/fashionimages/fashion/0390469004.jpg\n"
     ]
    }
   ],
   "source": [
    "# Connect to Blob Storage\n",
    "blob_service_client = BlobServiceClient.from_connection_string(blob_connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "blobs = container_client.list_blobs()\n",
    "\n",
    "first_blob = next(blobs)\n",
    "blob_url = container_client.get_blob_client(first_blob).url\n",
    "print(f\"URL of the first blob: {blob_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the Azure AI Search client\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Setting the Azure AI Search client\n",
    "    print(\"Setting the Azure AI Search client\")\n",
    "    \n",
    "    search_client = SearchClient(endpoint=azure_search_endpoint,\n",
    "                                 index_name=index_name,\n",
    "                                 credential=AzureKeyCredential(azure_search_key)\n",
    "                                )\n",
    "    print(\"Done\")\n",
    "\n",
    "except:\n",
    "    print(f\"‚ùå Request failed. Cannot create Azure AI Search client: {azure_search_endpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Azure AI Search index status for: fashion-demo-2025\n",
      "\n",
      "{\n",
      "  \"@odata.context\": \"https://azureaisearch-sr.search.windows.net/$metadata#Microsoft.Azure.Search.V2024_07_01.IndexStatistics\",\n",
      "  \"documentCount\": 10226,\n",
      "  \"storageSize\": 115931376,\n",
      "  \"vectorIndexSize\": 42451784\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "document_count, storage_size = get_index_stats(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Number of documents in the index = 10,226\n",
      "üìè Size of the index = 110.56 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"üî¢ Number of documents in the index = {document_count:,}\")\n",
    "print(f\"üìè Size of the index = {storage_size / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Webapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn = 5\n",
    "imgsize = 512\n",
    "\n",
    "footnote = \"‚ú® Powered by Azure AI Foundry, Azure AI Vision and Azure AI Search.\"\n",
    "header_prompt = \"üîç Visual Search with Azure AI using a prompt\"\n",
    "header_images = \"üì∏ Visual Search with Azure AI using an image\"\n",
    "\n",
    "#logo_image = \"https://github.com/retkowsky/images/blob/master/banni%C3%A8re.jpg?raw=true\"\n",
    "#image = \"<center> <img src= {} width=1024px></center>\".format(logo_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Prompt webapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webapp_prompt_fn(prompt: str, topn: int = 5) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Handles the prompt-based image search for the Gradio web application.\n",
    "\n",
    "    Parameters:\n",
    "    - prompt (str): The natural language query describing the desired image content.\n",
    "    - topn (int, optional): The number of top matching results to return. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "    - List[Tuple[str, str]]: A list of tuples where each tuple contains:\n",
    "        - The file path to the matched image.\n",
    "        - A formatted string with the image filename and its similarity score.\n",
    "    \n",
    "    Notes:\n",
    "    - This function relies on `prompt_search_gradio` to retrieve the top matching image paths,\n",
    "      their similarity scores, and filenames based on the input prompt.\n",
    "    \"\"\"\n",
    "    # Assuming prompt_search_gradio can return file paths\n",
    "    file_paths, scores, filenames = prompt_search_gradio(prompt, topn)\n",
    "    \n",
    "    return [\n",
    "        (file_path, f\"Image: {filename}\\nwith score = {score:.5f}\")\n",
    "        for file_path, score, filename in zip(file_paths, scores, filenames)\n",
    "    ]\n",
    "\n",
    "\n",
    "prompt_examples = [\n",
    "    [\"T-shirt with 'Paris' text on it\", 3],\n",
    "    [\"Some torn blue jeans\", 3],\n",
    "    [\"I want some sneakers with birds on it\", 3],\n",
    "    [\"I want a beautiful hat.\", 3],\n",
    "    [\"Ray ban with leopard frames\", 3],\n",
    "]\n",
    "\n",
    "\n",
    "with gr.Blocks(title=\"üñºÔ∏è Visual Search WebApp\") as webapp_prompt:\n",
    "    gr.Markdown(f\"## {header_prompt}\")\n",
    "    #gr.Markdown(image)\n",
    "\n",
    "    with gr.Row():\n",
    "        prompt_input = gr.Textbox(\n",
    "            lines=2,\n",
    "            label=\"üîç What do you want to search?\",\n",
    "            placeholder=\"üí°Enter your prompt to search the products database...\"\n",
    "        )\n",
    "        topn_slider = gr.Slider(minimum=1,\n",
    "                                maximum=10,\n",
    "                                value=3,\n",
    "                                step=1,\n",
    "                                label=\"üìä Top N\")\n",
    "\n",
    "    submit_button = gr.Button(\"üöÄ SEARCH IMAGES\")\n",
    "\n",
    "    # Output Gallery shown AFTER the button\n",
    "    gallery_output = gr.Gallery(label=\"üéØ Search results\",\n",
    "                                columns=3,\n",
    "                                height=\"auto\")\n",
    "\n",
    "    # Set up the interaction\n",
    "    submit_button.click(fn=webapp_prompt_fn,\n",
    "                        inputs=[prompt_input, topn_slider],\n",
    "                        outputs=gallery_output)\n",
    "\n",
    "    gr.Markdown(\"### üí° Example prompts\")\n",
    "    gr.Examples(examples=prompt_examples, inputs=[prompt_input, topn_slider])\n",
    "\n",
    "    gr.Markdown(footnote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_search_gradio(\n",
    "        prompt: str,\n",
    "        topn: int = 5) -> Tuple[List[Image.Image], List[float], List[str]]:\n",
    "    \"\"\"\n",
    "    Performs a semantic search on an Azure AI Search index using a text prompt and returns the top matching images.\n",
    "\n",
    "    Parameters:\n",
    "    - prompt (str): The natural language query used to search for similar images.\n",
    "    - topn (int, optional): The number of top results to retrieve. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[List[Image.Image], List[float], List[str]]:\n",
    "        - A list of PIL Image objects corresponding to the top search results.\n",
    "        - A list of similarity scores (floats) for each result.\n",
    "        - A list of filenames (str) for the matched images.\n",
    "\n",
    "    Behavior:\n",
    "    - Converts the input prompt into a vector using `text_embedding`.\n",
    "    - Queries the Azure AI Search index using vector similarity search.\n",
    "    - Retrieves the top matching image filenames and their similarity scores.\n",
    "    - Downloads and resizes the corresponding images from Azure Blob Storage.\n",
    "\n",
    "    Notes:\n",
    "    - If an image fails to load, it is skipped with an error message.\n",
    "    - Any exceptions during the search process are caught and logged.\n",
    "    \"\"\"\n",
    "    images_list = []\n",
    "    scores_list = []\n",
    "    search_results = []\n",
    "\n",
    "    try:\n",
    "        # Azure Search client setup\n",
    "        search_client = SearchClient(endpoint=azure_search_endpoint,\n",
    "                                     index_name=index_name,\n",
    "                                     credential=AzureKeyCredential(azure_search_key)\n",
    "                                    )\n",
    "\n",
    "        query_vector = text_embedding(prompt)\n",
    "\n",
    "        response = search_client.search(search_text=None,\n",
    "                                        vector_queries=[\n",
    "                                            VectorizedQuery(\n",
    "                                                vector=query_vector,\n",
    "                                                k_nearest_neighbors=topn,\n",
    "                                                fields=\"imagevector\")\n",
    "                                        ])\n",
    "\n",
    "        for idx, doc in enumerate(response, start=1):\n",
    "            filename = doc.get(\"imagefile\")\n",
    "            score = doc.get(\"@search.score\", 0.0)\n",
    "\n",
    "            if filename:\n",
    "                print(f\"Top {idx:02}: {filename} with Cosine Similarity = {score:.5f}\")\n",
    "                search_results.append(filename)\n",
    "                scores_list.append(score)\n",
    "\n",
    "        for filename in search_results:\n",
    "            try:\n",
    "                blob_client = container_client.get_blob_client(filename)\n",
    "                blob_data = blob_client.download_blob().readall()\n",
    "                img = Image.open(io.BytesIO(blob_data)).resize((imgsize, imgsize))\n",
    "                images_list.append(img)\n",
    "            except Exception as img_err:\n",
    "                print(f\"Failed to load image {filename}: {img_err}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Image search failed: {e}\")\n",
    "\n",
    "    return images_list, scores_list, search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webapp_prompt.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Image webapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_search_gradio(\n",
    "        imagefile: str,\n",
    "        topn: int = 5) -> Tuple[List[Image.Image], List[float], List[str]]:\n",
    "    \"\"\"\n",
    "    Performs a reverse image search using Azure AI Search and returns the top visually similar images.\n",
    "\n",
    "    Parameters:\n",
    "    - imagefile (str): The path or identifier of the input image to search with.\n",
    "    - topn (int, optional): The number of top similar images to retrieve. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[List[Image.Image], List[float], List[str]]:\n",
    "        - A list of PIL Image objects representing the top matching images.\n",
    "        - A list of similarity scores (floats) for each result.\n",
    "        - A list of filenames (str) corresponding to the matched images.\n",
    "\n",
    "    Behavior:\n",
    "    - Computes the embedding vector of the input image using `get_image_embedding`.\n",
    "    - Queries the Azure AI Search index using vector similarity search.\n",
    "    - Retrieves the top matching image filenames and their similarity scores.\n",
    "    - Downloads and resizes the matched images from Azure Blob Storage.\n",
    "\n",
    "    Notes:\n",
    "    - If an image fails to load, it is skipped with an error message.\n",
    "    - Any exceptions during the search or image retrieval process are caught and logged.\n",
    "    \"\"\"\n",
    "    images_list = []\n",
    "    scores_list = []\n",
    "    search_results = []\n",
    "\n",
    "    try:\n",
    "        # Azure Search client setup\n",
    "        search_client = SearchClient(endpoint=azure_search_endpoint,\n",
    "                                     index_name=index_name,\n",
    "                                     credential=AzureKeyCredential(azure_search_key)\n",
    "                                    )\n",
    "\n",
    "        query_vector = get_image_embedding(imagefile)\n",
    "\n",
    "        response = search_client.search(search_text=None,\n",
    "                                        vector_queries=[\n",
    "                                            VectorizedQuery(\n",
    "                                                vector=query_vector,\n",
    "                                                k_nearest_neighbors=topn,\n",
    "                                                fields=\"imagevector\")\n",
    "                                        ])\n",
    "\n",
    "        for idx, doc in enumerate(response, start=1):\n",
    "            filename = doc.get(\"imagefile\")\n",
    "            score = doc.get(\"@search.score\", 0.0)\n",
    "\n",
    "            if filename:\n",
    "                print(f\"Top {idx:02}: {filename} with Cosine Similarity = {score:.5f}\")\n",
    "                search_results.append(filename)\n",
    "                scores_list.append(score)\n",
    "\n",
    "        for filename in search_results:\n",
    "            try:\n",
    "                blob_client = container_client.get_blob_client(filename)\n",
    "                blob_data = blob_client.download_blob().readall()\n",
    "                img = Image.open(io.BytesIO(blob_data)).resize((imgsize, imgsize))\n",
    "                images_list.append(img)\n",
    "            except Exception as img_err:\n",
    "                print(f\"Failed to load image {filename}: {img_err}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Image search failed: {e}\")\n",
    "\n",
    "    return images_list, scores_list, search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webapp_image_fn(prompt: str,\n",
    "                    topn: int = 5) -> List[Tuple[Image.Image, str]]:\n",
    "    \"\"\"\n",
    "    Handles reverse image search for the Gradio web application using an uploaded image file path.\n",
    "\n",
    "    Parameters:\n",
    "    - prompt (str): The file path of the uploaded image used as the search query.\n",
    "    - topn (int, optional): The number of top similar images to retrieve. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "    - List[Tuple[Image.Image, str]]: A list of tuples, each containing:\n",
    "        - A PIL Image object representing a similar image.\n",
    "        - A formatted string with the image filename and its similarity score.\n",
    "\n",
    "    Notes:\n",
    "    - This function wraps the `image_search_gradio` function to format the results for display in a Gradio Gallery component.\n",
    "    - The `prompt` parameter is expected to be a valid image file path, not a text prompt.\n",
    "    \"\"\"\n",
    "    images, scores, filenames = image_search_gradio(prompt, topn)\n",
    "    \n",
    "    return [(img, f\"Image: {filename}\\n with score = {score:.5f}\")\n",
    "            for img, score, filename in zip(images, scores, filenames)]\n",
    "\n",
    "\n",
    "images_examples = [\n",
    "    [\"sources/image1.jpg\", 3],\n",
    "    [\"sources/image2.jpg\", 3],\n",
    "    [\"sources/image3.jpg\", 3],\n",
    "    [\"sources/image4.jpg\", 3],\n",
    "    [\"sources/image5.jpg\", 3],\n",
    "]\n",
    "\n",
    "\n",
    "with gr.Blocks(title=\"üñºÔ∏è Visual Search WebApp\") as webapp_image:\n",
    "    gr.Markdown(f\"## {header_images}\")\n",
    "    #gr.Markdown(image)\n",
    "\n",
    "    with gr.Row():\n",
    "        prompt_input = gr.File(label=\"üîç Select an image\")\n",
    "        topn_slider = gr.Slider(minimum=1,\n",
    "                                maximum=10,\n",
    "                                value=3,\n",
    "                                step=1,\n",
    "                                label=\"üìä Top N\")\n",
    "\n",
    "    # Display the uploaded image\n",
    "    uploaded_image_display = gr.Image(label=\"üì• Uploaded image\",\n",
    "                                      type=\"filepath\")\n",
    "\n",
    "    # Update the image display when a file is uploaded\n",
    "    prompt_input.change(fn=lambda f: f.name if f else None,\n",
    "                        inputs=prompt_input,\n",
    "                        outputs=uploaded_image_display)\n",
    "\n",
    "    submit_button = gr.Button(\"üöÄ SEARCH SIMILAR IMAGES\")\n",
    "\n",
    "    gallery_output = gr.Gallery(label=\"üéØ Search results\",\n",
    "                                columns=3,\n",
    "                                height=\"auto\")\n",
    "\n",
    "    submit_button.click(fn=webapp_image_fn,\n",
    "                        inputs=[prompt_input, topn_slider],\n",
    "                        outputs=gallery_output)\n",
    "\n",
    "    gr.Markdown(\"### üí° Example prompts\")\n",
    "    gr.Examples(examples=images_examples, inputs=[prompt_input, topn_slider])\n",
    "\n",
    "    gr.Markdown(footnote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webapp_image.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Compose images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_prompt_examples = [\n",
    "    [\n",
    "        \"Create a photorealistic image of a man. He is wearing the 4 clothing items shown in the reference images. This man is walking along a busy city street, with the Eiffel Tower clearly visible in the background. A German Shepherd dog is walking closely beside him.\"\n",
    "    ],\n",
    "    [\n",
    "        \"Create a photorealistic image of a man. He is wearing the 4 clothing items shown in the reference images. This man is walking along a quiet city street, close to a park, with the Sydney Opera House visible in the background. A Labrador retriever dog is walking closely beside him.\"\n",
    "    ],\n",
    "    [\n",
    "        \"Create a photorealistic image of a man. He is wearing the 4 clothing items shown in the reference images. This man is sitting on a chair using a Windows laptop in a cosy apartment. A cat is on the ground. We can see the rain outside from the window.\"\n",
    "    ],\n",
    "    [\n",
    "        \"Create a photorealistic image of a man. He is wearing the 4 clothing items shown in the reference images. He is walking close to a swimming pool. A young child walks closely beside him. The sky in the background should appear sunny.\"\n",
    "    ],\n",
    "    [\n",
    "        \"Create a Studio Ghibli image of a man. He is wearing the 4 clothing items shown in the reference images. The man is close to a pink Rolls-Royce car.\"\n",
    "    ],\n",
    "    [\n",
    "        \"Create an image in the style of Edward Hopper of a man. He is wearing the 4 clothing items shown in the reference images. This man is outside a pub during a rainy day. He is waiting outside the pub with a couple of friends, close to a red phone booth.\"\n",
    "    ],\n",
    "    [\n",
    "        \"Combine the images to generate an avatar. Use cartoon style.\"\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_compose_fn(source_images: List[str],\n",
    "                     prompt: str,\n",
    "                     n: int = 1,\n",
    "                     size: str = \"1024x1024\",\n",
    "                     quality: str = \"high\") -> Optional[List[str]]:\n",
    "    \"\"\"\n",
    "    Sends a set of source images and a text prompt to an Azure OpenAI image composition endpoint\n",
    "    to generate new AI-composed images.\n",
    "\n",
    "    Parameters:\n",
    "    - source_images (List[str]): List of file paths to the source images to be composed.\n",
    "    - prompt (str): A natural language description guiding how the images should be composed.\n",
    "    - n (int, optional): Number of composed images to generate. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "    - Optional[List[str]]: A list of file paths to the generated images if successful, or None if an error occurs.\n",
    "\n",
    "    Behavior:\n",
    "    - Validates the Azure OpenAI endpoint and API key from environment variables.\n",
    "    - Constructs a POST request to the Azure OpenAI image composition API with the provided images and prompt.\n",
    "    - Decodes the base64-encoded image responses and saves them as JPEG files in a `generated_images` directory.\n",
    "    - Returns the file paths of the saved images.\n",
    "\n",
    "    Notes:\n",
    "    - Automatically creates the output directory if it doesn't exist.\n",
    "    - Handles and logs exceptions during the request or image processing steps.\n",
    "    - Closes all file handles after the request is made.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        IMAGESGEN_DIR = \"generated_images\"\n",
    "        os.makedirs(IMAGESGEN_DIR, exist_ok=True)\n",
    "\n",
    "        files = [(\"image[]\", open(image, \"rb\")) for image in source_images]\n",
    "        headers = {\"api-key\": os.getenv(\"key\")}\n",
    "        endpoint = os.getenv(\"endpoint\")\n",
    "\n",
    "        if not endpoint:\n",
    "            raise ValueError(\n",
    "                \"AZURE_OPENAI_ENDPOINT environment variable not set\")\n",
    "\n",
    "        aoai_name = re.search(r'https://(.*?)/openai', endpoint).group(1)\n",
    "        url = f\"https://{aoai_name}/openai/deployments/gpt-image-1/images/edits?api-version=2025-04-01-preview\"\n",
    "\n",
    "        data = {\n",
    "            \"prompt\": prompt,\n",
    "            \"n\": n,  # Number of images to generate\n",
    "            \"size\": size,   # Options: 1024x1024, 1536x1024, 1024x1536\n",
    "            \"quality\": quality, # option: low, medium, high\n",
    "            \"output_compression\": 100,\n",
    "            \"output_format\": \"jpeg\",\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, headers=headers, files=files, data=data)\n",
    "        response.raise_for_status()\n",
    "        images_data = response.json()[\"data\"]\n",
    "        encoded_images = [img[\"b64_json\"] for img in images_data]\n",
    "\n",
    "        # Close file handles\n",
    "        for _, file_handle in files:\n",
    "            file_handle.close()\n",
    "\n",
    "        # Parse generated images\n",
    "        output_images_list = []\n",
    "        \n",
    "        for encoded_image in encoded_images:\n",
    "            img = Image.open(BytesIO(base64.b64decode(encoded_image)))\n",
    "            # Save image to file\n",
    "            now = str(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")[:-3])\n",
    "            output_file = os.path.join(IMAGESGEN_DIR, f\"compose_{now}.jpg\")\n",
    "            img.save(output_file)\n",
    "            print(f\"‚úÖ Generated AI image file is saved: {output_file}\")\n",
    "            output_images_list.append(output_file)\n",
    "\n",
    "        return output_images_list\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating images: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_uploaded_images(files):\n",
    "    \"\"\"\n",
    "    Processes a list of uploaded image files for preview and returns their paths and a status message.\n",
    "\n",
    "    Parameters:\n",
    "    - files (List[UploadedFile]): A list of uploaded file objects (e.g., from a Gradio File component).\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[List[PIL.Image.Image], str]:\n",
    "        - A list of PIL Image objects for preview display.\n",
    "        - A status message indicating the number of successfully uploaded images or an error message if none were uploaded.\n",
    "\n",
    "    Behavior:\n",
    "    - Checks if any files were uploaded.\n",
    "    - For each valid file:\n",
    "        - Extracts the file path.\n",
    "        - Loads the image using PIL for preview.\n",
    "    - Returns the list of preview images and a success message.\n",
    "    \"\"\"\n",
    "    if not files:\n",
    "        return [], \"No images uploaded\"\n",
    "\n",
    "    image_paths = []\n",
    "    preview_images = []\n",
    "\n",
    "    for file in files:\n",
    "        if file is not None:\n",
    "            # Copy uploaded file to temporary location\n",
    "            temp_path = file.name\n",
    "            image_paths.append(temp_path)\n",
    "            # Load image for preview\n",
    "            img = Image.open(temp_path)\n",
    "            preview_images.append(img)\n",
    "\n",
    "    status = f\"‚úÖ Uploaded {len(image_paths)} images successfully\"\n",
    "    \n",
    "    return preview_images, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_composed_images(uploaded_files, prompt, num_images, size, quality):\n",
    "    \"\"\"\n",
    "    Generates new images based on uploaded input images and a text prompt using an image composition function.\n",
    "\n",
    "    Parameters:\n",
    "    - uploaded_files (List[UploadedFile]): A list of uploaded image files (e.g., from a Gradio File component).\n",
    "    - prompt (str): A text prompt describing the desired transformation or composition.\n",
    "    - num_images (int): The number of composed images to generate.\n",
    "    - size (str): 1024x1024, 1536x1024, 1024x1536\n",
    "    - quality (str): low, medium, high\n",
    "    \n",
    "    Returns:\n",
    "    - Tuple[List[PIL.Image.Image], str]:\n",
    "        - A list of generated PIL Image objects.\n",
    "        - A status message indicating success or failure.\n",
    "\n",
    "    Behavior:\n",
    "    - Validates that at least one image is uploaded and a prompt is provided.\n",
    "    - Extracts file paths from the uploaded files.\n",
    "    - Calls `image_compose_fn` to generate new images based on the input.\n",
    "    - Loads the generated images for display.\n",
    "    - Handles and reports any errors during the generation process.\n",
    "    \"\"\"\n",
    "    if not uploaded_files:\n",
    "        return [], \"‚ùå Please upload at least one image first\"\n",
    "\n",
    "    if not prompt.strip():\n",
    "        return [], \"‚ùå Please enter a prompt\"\n",
    "\n",
    "    # Extract file paths from uploaded files\n",
    "    image_paths = [file.name for file in uploaded_files if file is not None]\n",
    "\n",
    "    if not image_paths:\n",
    "        return [], \"‚ùå No valid images found\"\n",
    "\n",
    "    # Call your image composition function\n",
    "    try:\n",
    "        result_paths = image_compose_fn(image_paths, prompt, int(num_images), size=size, quality=quality)\n",
    "\n",
    "        if result_paths:\n",
    "            # Load generated images for display\n",
    "            generated_images = []\n",
    "            for path in result_paths:\n",
    "                img = Image.open(path)\n",
    "                generated_images.append(img)\n",
    "\n",
    "            status = f\"‚úÖ Successfully generated {len(generated_images)} images\"\n",
    "            return generated_images, status\n",
    "        else:\n",
    "            return [], \"‚ùå Failed to generate images\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return [], f\"‚ùå Error during generation: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gradio_app():\n",
    "    \"\"\"\n",
    "    Creates and returns a Gradio web application for AI-based image composition.\n",
    "\n",
    "    Returns:\n",
    "    - gr.Blocks: A configured Gradio Blocks interface for uploading images, entering prompts, and generating composed images.\n",
    "\n",
    "    Features:\n",
    "    - Users can upload multiple images.\n",
    "    - A text prompt guides the AI on how to compose the uploaded images.\n",
    "    - A slider allows users to choose how many composed images to generate.\n",
    "    - Displays previews of uploaded images and the generated results.\n",
    "    - Includes example prompts to help users get started.\n",
    "\n",
    "    Components:\n",
    "    - File upload input for multiple images.\n",
    "    - Textbox for composition prompt.\n",
    "    - Slider to select number of images to generate.\n",
    "    - Button to trigger image generation.\n",
    "    - Galleries to preview uploaded and generated images.\n",
    "    - Status messages for upload and generation steps.\n",
    "    - Example prompts section for inspiration.\n",
    "\n",
    "    Notes:\n",
    "    - Uses `process_uploaded_images` to handle file uploads.\n",
    "    - Uses `generate_composed_images` to generate new images based on the prompt and uploaded files.\n",
    "    \"\"\"\n",
    "    with gr.Blocks(title=\"AI Image Composer\",\n",
    "                   theme=gr.themes.Soft()) as webapp_genimage:\n",
    "        \n",
    "        gr.Markdown(\"# üé® AI Image Composer\")\n",
    "        gr.Markdown(\"Upload multiple images and use AI to compose them into new creations!\")\n",
    "        #gr.Markdown(image)\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                gr.Markdown(\"### üìÅ 1. Upload images\")\n",
    "                uploaded_files = gr.File(label=\"Select Images to use\",\n",
    "                                         file_count=\"multiple\",\n",
    "                                         file_types=[\"image\"],\n",
    "                                         type=\"filepath\")\n",
    "\n",
    "                upload_status = gr.Textbox(label=\"Images upload status\",\n",
    "                                           interactive=False,\n",
    "                                           lines=1)\n",
    "\n",
    "                gr.Markdown(\"### ‚úèÔ∏è 2. Composition prompt\")\n",
    "                prompt_input = gr.Textbox(\n",
    "                    label=\"Prompt\",\n",
    "                    placeholder=\"Describe how you want the images to be composed...\",\n",
    "                    lines=3)\n",
    "\n",
    "                images_resolution = gr.Radio(\n",
    "                    label=\"Resolution of the images to generate with gpt-image-1\",\n",
    "                    choices=[\"1024x1024\", \"1536x1024\", \"1024x1536\"],\n",
    "                    value=\"1024x1024\",\n",
    "                )\n",
    "\n",
    "                images_quality = gr.Radio(\n",
    "                    label=\"Quality of the images to generate with gpt-image-1\",\n",
    "                    choices=[\"low\", \"medium\", \"high\"],\n",
    "                    value=\"high\",\n",
    "                )\n",
    "\n",
    "                images_number = gr.Slider(\n",
    "                    label=\"Nomber of the images to generate with gpt-image-1\",\n",
    "                    minimum=1,\n",
    "                    maximum=5,\n",
    "                    value=3,\n",
    "                    step=1,\n",
    "                )\n",
    "\n",
    "                generate_btn = gr.Button(\"üé® GENERATED COMPOSED IMAGES\",\n",
    "                                         variant=\"primary\",\n",
    "                                         size=\"lg\")\n",
    "\n",
    "                generation_status = gr.Textbox(label=\"Generation status\",\n",
    "                                               interactive=False,\n",
    "                                               lines=1)\n",
    "\n",
    "            with gr.Column(scale=2):\n",
    "                gr.Markdown(\"### üëÄ Uploaded images preview\")\n",
    "                uploaded_gallery = gr.Gallery(label=\"Uploaded images\",\n",
    "                                              show_label=True,\n",
    "                                              elem_id=\"uploaded_gallery\",\n",
    "                                              columns=3,\n",
    "                                              rows=2,\n",
    "                                              height=\"500px\")\n",
    "\n",
    "                gr.Markdown(\"### üéØ Generated images\")\n",
    "                generated_gallery = gr.Gallery(label=\"Composed images\",\n",
    "                                               show_label=True,\n",
    "                                               elem_id=\"generated_gallery\",\n",
    "                                               columns=2,\n",
    "                                               rows=2,\n",
    "                                               height=\"700px\")\n",
    "\n",
    "        # Event handlers\n",
    "        uploaded_files.change(fn=process_uploaded_images,\n",
    "                              inputs=[uploaded_files],\n",
    "                              outputs=[uploaded_gallery, upload_status])\n",
    "\n",
    "        generate_btn.click(fn=generate_composed_images,\n",
    "                           inputs=[uploaded_files, prompt_input, images_number, images_resolution, images_quality],\n",
    "                           outputs=[generated_gallery, generation_status])\n",
    "\n",
    "        # Add example section\n",
    "        gr.Markdown(\"### üí° Example prompts\")\n",
    "        gr.Examples(\n",
    "            examples=gen_prompt_examples,\n",
    "            inputs=[prompt_input],\n",
    "        )\n",
    "        gr.Markdown(footnote)\n",
    "\n",
    "    return webapp_genimage\n",
    "\n",
    "\n",
    "webapp_genimage = create_gradio_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webapp_genimage.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final webapp: Combining the three gradio apps into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "professional_css = \"\"\"\n",
    "/* Main theme and layout */\n",
    "body {\n",
    "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "    margin: 0;\n",
    "    padding: 0;\n",
    "}\n",
    "\n",
    "/* Main container styling */\n",
    ".gradio-container {\n",
    "    max-width: 1400px;\n",
    "    margin: 0 auto;\n",
    "    background: rgba(255, 255, 255, 0.95);\n",
    "    border-radius: 20px;\n",
    "    box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);\n",
    "    backdrop-filter: blur(10px);\n",
    "    margin-top: 20px;\n",
    "    margin-bottom: 20px;\n",
    "}\n",
    "\n",
    "/* Header styling */\n",
    ".app-header {\n",
    "    text-align: center;\n",
    "    padding: 2rem 0;\n",
    "    background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);\n",
    "    border-radius: 20px 20px 0 0;\n",
    "    color: white;\n",
    "    margin-bottom: 2rem;\n",
    "}\n",
    "\n",
    ".app-title {\n",
    "    font-size: 2.5rem;\n",
    "    font-weight: 700;\n",
    "    margin-bottom: 0.5rem;\n",
    "    text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);\n",
    "}\n",
    "\n",
    ".app-subtitle {\n",
    "    font-size: 1.2rem;\n",
    "    opacity: 0.9;\n",
    "    font-weight: 300;\n",
    "}\n",
    "\n",
    "/* Tab styling */\n",
    ".tab-nav {\n",
    "    background: #f8f9fa;\n",
    "    border-radius: 15px;\n",
    "    padding: 1rem;\n",
    "    margin-bottom: 2rem;\n",
    "    box-shadow: inset 0 2px 4px rgba(0, 0, 0, 0.06);\n",
    "}\n",
    "\n",
    ".tab-nav button {\n",
    "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "    border: none;\n",
    "    color: white;\n",
    "    padding: 1rem 2rem;\n",
    "    border-radius: 12px;\n",
    "    font-weight: 600;\n",
    "    font-size: 1rem;\n",
    "    transition: all 0.3s ease;\n",
    "    margin: 0 0.5rem;\n",
    "    box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);\n",
    "}\n",
    "\n",
    "/* Make Generated Images tab bigger and more prominent */\n",
    ".tab-nav button:nth-child(3) {\n",
    "    padding: 1.5rem 3rem;\n",
    "    font-size: 1.2rem;\n",
    "    font-weight: 700;\n",
    "    background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%);\n",
    "    box-shadow: 0 6px 20px rgba(255, 107, 107, 0.4);\n",
    "    transform: scale(1.1);\n",
    "    border: 2px solid rgba(255, 255, 255, 0.3);\n",
    "}\n",
    "\n",
    ".tab-nav button:hover {\n",
    "    transform: translateY(-2px);\n",
    "    box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6);\n",
    "}\n",
    "\n",
    ".tab-nav button:nth-child(3):hover {\n",
    "    transform: scale(1.15) translateY(-3px);\n",
    "    box-shadow: 0 8px 25px rgba(255, 107, 107, 0.6);\n",
    "}\n",
    "\n",
    ".tab-nav button.selected {\n",
    "    background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);\n",
    "    transform: translateY(-1px);\n",
    "}\n",
    "\n",
    ".tab-nav button:nth-child(3).selected {\n",
    "    background: linear-gradient(135deg, #ff9ff3 0%, #f368e0 100%);\n",
    "    transform: scale(1.15) translateY(-2px);\n",
    "    box-shadow: 0 10px 30px rgba(243, 104, 224, 0.5);\n",
    "}\n",
    "\n",
    "/* Generated Images section specific styling */\n",
    ".tab-content:nth-child(3) {\n",
    "    padding: 3rem;\n",
    "    background: linear-gradient(135deg, rgba(255, 107, 107, 0.05) 0%, rgba(238, 90, 36, 0.05) 100%);\n",
    "    border-radius: 20px;\n",
    "    margin: 1rem 0;\n",
    "    min-height: 80vh;\n",
    "}\n",
    "\n",
    ".tab-content:nth-child(3) .input-container {\n",
    "    padding: 3rem;\n",
    "    border: 3px solid rgba(255, 107, 107, 0.3);\n",
    "    background: linear-gradient(135deg, rgba(255, 255, 255, 0.95) 0%, rgba(255, 249, 249, 0.95) 100%);\n",
    "}\n",
    "\n",
    ".tab-content:nth-child(3) .results-container {\n",
    "    padding: 3rem;\n",
    "    border-left: 6px solid #ff6b6b;\n",
    "    background: linear-gradient(135deg, rgba(255, 255, 255, 0.98) 0%, rgba(255, 249, 249, 0.98) 100%);\n",
    "    min-height: 60vh;\n",
    "}\n",
    "\n",
    "/* Make generated images display larger */\n",
    ".tab-content:nth-child(3) img {\n",
    "    max-width: 100%;\n",
    "    border-radius: 20px;\n",
    "    box-shadow: 0 15px 35px rgba(255, 107, 107, 0.3);\n",
    "    transition: all 0.3s ease;\n",
    "}\n",
    "\n",
    ".tab-content:nth-child(3) img:hover {\n",
    "    transform: scale(1.02);\n",
    "    box-shadow: 0 20px 40px rgba(255, 107, 107, 0.4);\n",
    "}\n",
    "\n",
    "/* Input styling */\n",
    ".input-container {\n",
    "    background: white;\n",
    "    border-radius: 15px;\n",
    "    padding: 2rem;\n",
    "    margin-bottom: 2rem;\n",
    "    box-shadow: 0 8px 25px rgba(0, 0, 0, 0.08);\n",
    "    border: 1px solid rgba(102, 126, 234, 0.1);\n",
    "}\n",
    "\n",
    "input[type=\"text\"], textarea {\n",
    "    border: 2px solid #e9ecef;\n",
    "    border-radius: 12px;\n",
    "    padding: 1rem;\n",
    "    font-size: 1rem;\n",
    "    transition: all 0.3s ease;\n",
    "    background: #f8f9fa;\n",
    "}\n",
    "\n",
    "input[type=\"text\"]:focus, textarea:focus {\n",
    "    border-color: #4facfe;\n",
    "    background: white;\n",
    "    box-shadow: 0 0 0 3px rgba(79, 172, 254, 0.1);\n",
    "    outline: none;\n",
    "}\n",
    "\n",
    "/* Button styling */\n",
    ".btn-primary {\n",
    "    background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);\n",
    "    border: none;\n",
    "    color: white;\n",
    "    padding: 1rem 2rem;\n",
    "    border-radius: 12px;\n",
    "    font-weight: 600;\n",
    "    font-size: 1.1rem;\n",
    "    cursor: pointer;\n",
    "    transition: all 0.3s ease;\n",
    "    box-shadow: 0 4px 15px rgba(79, 172, 254, 0.4);\n",
    "}\n",
    "\n",
    ".btn-primary:hover {\n",
    "    transform: translateY(-2px);\n",
    "    box-shadow: 0 6px 20px rgba(79, 172, 254, 0.6);\n",
    "}\n",
    "\n",
    "/* Results container */\n",
    ".results-container {\n",
    "    background: white;\n",
    "    border-radius: 15px;\n",
    "    padding: 2rem;\n",
    "    margin-top: 2rem;\n",
    "    box-shadow: 0 8px 25px rgba(0, 0, 0, 0.08);\n",
    "    border-left: 4px solid #4facfe;\n",
    "}\n",
    "\n",
    "/* Image upload area */\n",
    ".image-upload {\n",
    "    border: 3px dashed #4facfe;\n",
    "    border-radius: 15px;\n",
    "    padding: 3rem;\n",
    "    text-align: center;\n",
    "    background: rgba(79, 172, 254, 0.05);\n",
    "    transition: all 0.3s ease;\n",
    "}\n",
    "\n",
    ".image-upload:hover {\n",
    "    background: rgba(79, 172, 254, 0.1);\n",
    "    border-color: #00f2fe;\n",
    "}\n",
    "\n",
    "/* Progress and loading states */\n",
    ".progress-bar {\n",
    "    background: linear-gradient(90deg, #4facfe, #00f2fe);\n",
    "    height: 4px;\n",
    "    border-radius: 2px;\n",
    "    margin: 1rem 0;\n",
    "}\n",
    "\n",
    "/* Footer */\n",
    ".app-footer {\n",
    "    text-align: center;\n",
    "    padding: 2rem;\n",
    "    color: #6c757d;\n",
    "    border-top: 1px solid #e9ecef;\n",
    "    margin-top: 3rem;\n",
    "}\n",
    "\n",
    "/* Responsive design */\n",
    "@media (max-width: 768px) {\n",
    "    .gradio-container {\n",
    "        margin: 10px;\n",
    "        border-radius: 15px;\n",
    "    }\n",
    "    \n",
    "    .app-title {\n",
    "        font-size: 2rem;\n",
    "    }\n",
    "    \n",
    "    .tab-nav button {\n",
    "        padding: 0.8rem 1.5rem;\n",
    "        font-size: 0.9rem;\n",
    "        margin: 0.25rem;\n",
    "    }\n",
    "}\n",
    "\n",
    "/* Dark mode support */\n",
    "@media (prefers-color-scheme: dark) {\n",
    "    .input-container, .results-container {\n",
    "        background: #2d3748;\n",
    "        color: white;\n",
    "    }\n",
    "    \n",
    "    input[type=\"text\"], textarea {\n",
    "        background: #4a5568;\n",
    "        color: white;\n",
    "        border-color: #718096;\n",
    "    }\n",
    "}\n",
    "\n",
    "/* Animation for smooth transitions */\n",
    "* {\n",
    "    transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);\n",
    "}\n",
    "\n",
    "/* Custom scrollbar */\n",
    "::-webkit-scrollbar {\n",
    "    width: 8px;\n",
    "}\n",
    "\n",
    "::-webkit-scrollbar-track {\n",
    "    background: #f1f1f1;\n",
    "    border-radius: 10px;\n",
    "}\n",
    "\n",
    "::-webkit-scrollbar-thumb {\n",
    "    background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);\n",
    "    border-radius: 10px;\n",
    "}\n",
    "\n",
    "::-webkit-scrollbar-thumb:hover {\n",
    "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_titles = [\n",
    "    \"üîç Prompt search\",\n",
    "    \"üì∏ Image search\", \n",
    "    \"üé® AI image generation\"\n",
    "]\n",
    "\n",
    "\n",
    "visual_search_webapp = gr.TabbedInterface(\n",
    "    [webapp_prompt, webapp_image, webapp_genimage],\n",
    "    tab_titles,\n",
    "    title=\"Advanced Visual Search & AI Image Generation Platform with Azure AI\",\n",
    "    css=professional_css,\n",
    "    theme=gr.themes.Soft(\n",
    "        primary_hue=\"blue\",\n",
    "        secondary_hue=\"cyan\",\n",
    "        neutral_hue=\"slate\",\n",
    "        font=gr.themes.GoogleFont(\"Inter\"),\n",
    "        font_mono=gr.themes.GoogleFont(\"JetBrains Mono\")\n",
    "    ).set(\n",
    "        button_primary_background_fill=\"linear-gradient(135deg, #4facfe 0%, #00f2fe 100%)\",\n",
    "        button_primary_background_fill_hover=\"linear-gradient(135deg, #667eea 0%, #764ba2 100%)\",\n",
    "        block_radius=\"15px\",\n",
    "        container_radius=\"20px\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://313cd7afc0fbeefbd1.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://313cd7afc0fbeefbd1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 01: fashion/0623281002.jpg with Cosine Similarity = 0.61490\n",
      "Top 02: fashion/0626581003.jpg with Cosine Similarity = 0.61323\n",
      "Top 03: fashion/0623480002.jpg with Cosine Similarity = 0.61279\n",
      "Top 01: fashion/0694131021.jpg with Cosine Similarity = 0.62126\n",
      "Top 02: fashion/0691724010.jpg with Cosine Similarity = 0.61717\n",
      "Top 03: fashion/0640258011.jpg with Cosine Similarity = 0.61408\n",
      "Top 01: fashion/0625870004.jpg with Cosine Similarity = 0.62172\n",
      "Top 02: fashion/0620851002.jpg with Cosine Similarity = 0.60623\n",
      "Top 03: fashion/0625642002.jpg with Cosine Similarity = 0.60599\n",
      "Top 01: fashion/0646756002.jpg with Cosine Similarity = 0.61254\n",
      "Top 02: fashion/0696729002.jpg with Cosine Similarity = 0.60700\n",
      "Top 03: fashion/0646754002.jpg with Cosine Similarity = 0.60510\n",
      "Top 01: fashion/0623281002.jpg with Cosine Similarity = 0.61490\n",
      "Top 02: fashion/0626581003.jpg with Cosine Similarity = 0.61323\n",
      "Top 03: fashion/0623480002.jpg with Cosine Similarity = 0.61279\n",
      "Top 01: fashion/0698480005.jpg with Cosine Similarity = 0.60978\n",
      "Top 02: fashion/0694750003.jpg with Cosine Similarity = 0.60839\n",
      "Top 03: fashion/0394292001.jpg with Cosine Similarity = 0.60776\n",
      "Top 01: fashion/0646756002.jpg with Cosine Similarity = 0.61146\n",
      "Top 02: fashion/0696729002.jpg with Cosine Similarity = 0.60743\n",
      "Top 03: fashion/0696732003.jpg with Cosine Similarity = 0.60428\n",
      "Top 01: fashion/0625870004.jpg with Cosine Similarity = 0.62172\n",
      "Top 02: fashion/0620851002.jpg with Cosine Similarity = 0.60623\n",
      "Top 03: fashion/0625642002.jpg with Cosine Similarity = 0.60599\n",
      "Top 01: fashion/0623281002.jpg with Cosine Similarity = 0.61490\n",
      "Top 02: fashion/0626581003.jpg with Cosine Similarity = 0.61323\n",
      "Top 03: fashion/0623480002.jpg with Cosine Similarity = 0.61279\n",
      "Top 01: fashion/0698480005.jpg with Cosine Similarity = 0.60826\n",
      "Top 02: fashion/0694750003.jpg with Cosine Similarity = 0.60735\n",
      "Top 03: fashion/0394292001.jpg with Cosine Similarity = 0.60542\n",
      "Top 01: fashion/0646756002.jpg with Cosine Similarity = 0.60988\n",
      "Top 02: fashion/0696729002.jpg with Cosine Similarity = 0.60658\n",
      "Top 03: fashion/0646754002.jpg with Cosine Similarity = 0.60315\n",
      "Top 01: fashion/0625870004.jpg with Cosine Similarity = 0.62172\n",
      "Top 02: fashion/0620851002.jpg with Cosine Similarity = 0.60623\n",
      "Top 03: fashion/0625642002.jpg with Cosine Similarity = 0.60599\n",
      "Top 01: fashion/0699325004.jpg with Cosine Similarity = 0.80350\n",
      "Top 02: fashion/0647236001.jpg with Cosine Similarity = 0.79693\n",
      "Top 03: fashion/0694669002.jpg with Cosine Similarity = 0.79230\n",
      "Top 01: fashion/0646756002.jpg with Cosine Similarity = 0.79800\n",
      "Top 02: fashion/0696732003.jpg with Cosine Similarity = 0.78887\n",
      "Top 03: fashion/0623350004.jpg with Cosine Similarity = 0.78819\n",
      "Top 01: fashion/0694729001.jpg with Cosine Similarity = 0.81759\n",
      "Top 02: fashion/0642775001.jpg with Cosine Similarity = 0.80917\n",
      "Top 03: fashion/0694677001.jpg with Cosine Similarity = 0.80200\n",
      "‚úÖ Generated AI image file is saved: generated_images/compose_20250730_133028_168.jpg\n",
      "‚úÖ Generated AI image file is saved: generated_images/compose_20250730_133028_280.jpg\n",
      "‚úÖ Generated AI image file is saved: generated_images/compose_20250730_133028_325.jpg\n",
      "‚úÖ Generated AI image file is saved: generated_images/compose_20250730_133205_594.jpg\n",
      "‚úÖ Generated AI image file is saved: generated_images/compose_20250730_133205_667.jpg\n",
      "‚úÖ Generated AI image file is saved: generated_images/compose_20250730_133205_717.jpg\n",
      "‚úÖ Generated AI image file is saved: generated_images/compose_20250730_133336_611.jpg\n",
      "‚úÖ Generated AI image file is saved: generated_images/compose_20250730_133336_745.jpg\n",
      "‚úÖ Generated AI image file is saved: generated_images/compose_20250730_133336_878.jpg\n"
     ]
    }
   ],
   "source": [
    "visual_search_webapp.launch(\n",
    "        share=True,\n",
    "        show_error=True,\n",
    "        favicon_path=None,  # Add your favicon path here\n",
    "        auth=None,  # Add authentication if needed: (\"username\", \"password\")\n",
    "        max_threads=40, # By default, Gradio uses a thread pool (inherited from FastAPI) with a maximum of 40 threads.\n",
    "        debug=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Go to next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
