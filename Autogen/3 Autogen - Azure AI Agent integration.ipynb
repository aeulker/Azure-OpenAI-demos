{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Autogen - Azure AI Agent integration\n",
    "\n",
    "The AutoGen ecosystem provides everything you need to create AI agents, especially multi-agent workflows -- framework, developer tools, and applications.\n",
    "\n",
    "The framework uses a layered and extensible design. Layers have clearly divided responsibilities and build on top of layers below. This design enables you to use the framework at different levels of abstraction, from high-level APIs to low-level components.\n",
    "\n",
    "Core API implements message passing, event-driven agents, and local and distributed runtime for flexibility and power. It also support cross-language support for .NET and Python.\n",
    "AgentChat API implements a simpler but opinionated API for rapid prototyping. This API is built on top of the Core API and is closest to what users of v0.2 are familiar with and supports common multi-agent patterns such as two-agent chat or group chats.\n",
    "Extensions API enables first- and third-party extensions continuously expanding framework capabilities. It support specific implementation of LLM clients (e.g., OpenAI, AzureOpenAI), and capabilities such as code execution.\n",
    "\n",
    "<img src=\"https://github.com/microsoft/autogen/raw/main/autogen-landing.jpg\" width=400>\n",
    "\n",
    "> https://microsoft.github.io/autogen/stable/<br>\n",
    "> https://github.com/microsoft/autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import autogen\n",
    "import openai\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.projects.models import BingGroundingTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version = 3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]\n",
      "AutoGen version = 0.9.1post0\n",
      "OpenAI version: 1.79.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Python version = {sys.version}\")\n",
    "print(f\"AutoGen version = {autogen.__version__}\")\n",
    "print(f\"OpenAI version: {openai.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 21-May-2025 11:48:09\n"
     ]
    }
   ],
   "source": [
    "print(f\"Today is {datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"azure.env\")\n",
    "\n",
    "model = \"gpt-4o\"\n",
    "model_deploymenyt = \"gpt-4o\"\n",
    "connection_name = \"groundingbingsearch\"  # Yoiu must define a grouding bing search connection in Azure AI Foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=model_deploymenyt,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    "    model = model,\n",
    "    temperature = 0.7,\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_ad_token_provider=token_provider,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def web_ai_agent(query: str) -> str:\n",
    "    print(\"***** Bing for Azure AI Agent Service\\n\")\n",
    "    \n",
    "    project_client = AIProjectClient.from_connection_string(\n",
    "        credential=DefaultAzureCredential(),\n",
    "        conn_str=os.getenv(\"PROJECT_CONNECTION_STRING\"),\n",
    "    )\n",
    "       \n",
    "    with project_client:\n",
    "        bing_connection = project_client.connections.get(\n",
    "            connection_name=connection_name\n",
    "        )\n",
    "    \n",
    "        bing = BingGroundingTool(connection_id=bing_connection.id)\n",
    "    \n",
    "        agent = project_client.agents.create_agent(\n",
    "            model=model,\n",
    "            name=\"web-agent\",\n",
    "            instructions=\"\"\"        \n",
    "                You are a web search agent.\n",
    "                Your only tool is search_tool - use it to find information.\n",
    "                You make only one search call at a time.\n",
    "                Once you have the results, you never do calculations based on them.\n",
    "            \"\"\",\n",
    "            tools=bing.definitions,\n",
    "            headers={\"x-ms-enable-preview\": \"true\"}\n",
    "        )\n",
    "        print(f\"1. Created agent, ID: {agent.id}\")\n",
    "\n",
    "        # Create thread for communication\n",
    "        thread = project_client.agents.create_thread()\n",
    "        print(f\"2. Created thread, ID: {thread.id}\")\n",
    "\n",
    "        # Create message to thread\n",
    "        message = project_client.agents.create_message(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=query,\n",
    "        )\n",
    "        print(f\"3. Message: {message}\")\n",
    "        # Create and process agent run in thread with tools\n",
    "        run = project_client.agents.create_and_process_run(thread_id=thread.id, agent_id=agent.id)\n",
    "        print(f\"4. Run finished with status: {run.status}\")\n",
    "\n",
    "        if run.status == \"failed\":\n",
    "            print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "        # Fetch and log all messages\n",
    "        messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "        result = messages[\"data\"][0][\"content\"][0][\"text\"][\"value\"]\n",
    "  \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bing_search_agent = AssistantAgent(\n",
    "    name=\"bing_agent\",\n",
    "    model_client=client,\n",
    "    tools=[web_ai_agent],\n",
    "    system_message=\"Use tools to solve tasks.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main_agent(query) -> None:\n",
    "    response = await bing_search_agent.on_messages(\n",
    "            [TextMessage(content=query, source=\"user\")],\n",
    "            cancellation_token=CancellationToken(),\n",
    "    )\n",
    "    print(\"\\nFull response:\", response.chat_message)\n",
    "    print(\"\\033[1;31;34m\")\n",
    "    print(\"Answer:\", response.chat_message.content)\n",
    "\n",
    "    print(\"\\033[1;31;32m\")\n",
    "    if response.chat_message.type == \"TextMessage\":\n",
    "        print(\"Note: üö´ No Bing call search was made\")\n",
    "    elif response.chat_message.type == \"ToolCallSummaryMessage\":\n",
    "        print(\"Note: üîç A Bing call search was made\")\n",
    "    else:\n",
    "        print(\"‚ùìNA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple exemple with using the bing addon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Bing for Azure AI Agent Service\n",
      "\n",
      "1. Created agent, ID: asst_47ZmBpaGjM1sVO8LTNimWvW6\n",
      "2. Created thread, ID: thread_6D1gRrAcM54ICzOMWdNussHF\n",
      "3. Message: {'id': 'msg_vOX07hr1n5aOxfpdi6t9FgrB', 'object': 'thread.message', 'created_at': 1747828092, 'assistant_id': None, 'thread_id': 'thread_6D1gRrAcM54ICzOMWdNussHF', 'run_id': None, 'role': 'user', 'content': [{'type': 'text', 'text': {'value': 'hello', 'annotations': []}}], 'attachments': [], 'metadata': {}}\n",
      "4. Run finished with status: completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using  the agent that will always do a web search\n",
    "await web_ai_agent(\"hello\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full response: source='bing_agent' models_usage=RequestUsage(prompt_tokens=52, completion_tokens=12) metadata={} content='Hi there! How can I assist you today?' type='TextMessage'\n",
      "\u001b[1;31;34m\n",
      "Answer: Hi there! How can I assist you today?\n",
      "\u001b[1;31;32m\n",
      "Note: üö´ No Bing call search was made\n"
     ]
    }
   ],
   "source": [
    "# the main agent will use the llm\n",
    "await main_agent(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full response: source='bing_agent' models_usage=RequestUsage(prompt_tokens=804, completion_tokens=107) metadata={} content='An LLM, or Large Language Model, is a type of artificial intelligence algorithm designed to understand and generate human-like text. These models are trained on vast amounts of text data and use machine learning techniques to predict the likelihood of a word or sentence given the preceding context. This allows them to perform a range of natural language processing tasks such as translation, summarization, conversation, and more. Popular examples include GPT (Generative Pre-trained Transformer) models, which are designed to generate text that is coherent and contextually relevant.' type='TextMessage'\n",
      "\u001b[1;31;34m\n",
      "Answer: An LLM, or Large Language Model, is a type of artificial intelligence algorithm designed to understand and generate human-like text. These models are trained on vast amounts of text data and use machine learning techniques to predict the likelihood of a word or sentence given the preceding context. This allows them to perform a range of natural language processing tasks such as translation, summarization, conversation, and more. Popular examples include GPT (Generative Pre-trained Transformer) models, which are designed to generate text that is coherent and contextually relevant.\n",
      "\u001b[1;31;32m\n",
      "Note: üö´ No Bing call search was made\n"
     ]
    }
   ],
   "source": [
    "# the main agent will use the llm\n",
    "await main_agent(\"What is a LLM?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full response: source='bing_agent' models_usage=RequestUsage(prompt_tokens=926, completion_tokens=324) metadata={} content='Here are some of the top cities in France:\\n\\n1. **Paris**: Known for its iconic landmarks like the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral, Paris is a hub for art, fashion, gastronomy, and culture.\\n\\n2. **Marseille**: Located on the Mediterranean coast, Marseille is famous for its port, multicultural atmosphere, and sites like the Basilica of Notre-Dame de la Garde.\\n\\n3. **Lyon**: Recognized for its cuisine and historical architecture, Lyon is a UNESCO World Heritage site situated between the Rh√¥ne and Sa√¥ne rivers.\\n\\n4. **Toulouse**: Known as \"La Ville Rose\" for its terracotta buildings, Toulouse is a center for the aerospace industry with a vibrant cultural scene.\\n\\n5. **Nice**: Situated on the French Riviera, Nice is renowned for its beaches, Promenade des Anglais, and arts scene.\\n\\n6. **Bordeaux**: Famous for wine production, Bordeaux features a beautiful historic center and surrounding vineyards.\\n\\n7. **Lille**: Known for its Flemish influences, Lille offers charming old quarters and vibrant cultural events.\\n\\n8. **Nantes**: Celebrated for its innovative spirit, Nantes mixes historical architecture with modern art installations.\\n\\n9. **Strasbourg**: Famous for its Gothic cathedral and old town, Strasbourg hosts many European institutions and boasts a unique Franco-German culture.\\n\\n10. **Montpellier**: With a vibrant student population and Mediterranean climate, Montpellier combines old and modern architecture in a lively setting.\\n\\nEach of these cities offers a unique glimpse into French culture and lifestyle.' type='TextMessage'\n",
      "\u001b[1;31;34m\n",
      "Answer: Here are some of the top cities in France:\n",
      "\n",
      "1. **Paris**: Known for its iconic landmarks like the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral, Paris is a hub for art, fashion, gastronomy, and culture.\n",
      "\n",
      "2. **Marseille**: Located on the Mediterranean coast, Marseille is famous for its port, multicultural atmosphere, and sites like the Basilica of Notre-Dame de la Garde.\n",
      "\n",
      "3. **Lyon**: Recognized for its cuisine and historical architecture, Lyon is a UNESCO World Heritage site situated between the Rh√¥ne and Sa√¥ne rivers.\n",
      "\n",
      "4. **Toulouse**: Known as \"La Ville Rose\" for its terracotta buildings, Toulouse is a center for the aerospace industry with a vibrant cultural scene.\n",
      "\n",
      "5. **Nice**: Situated on the French Riviera, Nice is renowned for its beaches, Promenade des Anglais, and arts scene.\n",
      "\n",
      "6. **Bordeaux**: Famous for wine production, Bordeaux features a beautiful historic center and surrounding vineyards.\n",
      "\n",
      "7. **Lille**: Known for its Flemish influences, Lille offers charming old quarters and vibrant cultural events.\n",
      "\n",
      "8. **Nantes**: Celebrated for its innovative spirit, Nantes mixes historical architecture with modern art installations.\n",
      "\n",
      "9. **Strasbourg**: Famous for its Gothic cathedral and old town, Strasbourg hosts many European institutions and boasts a unique Franco-German culture.\n",
      "\n",
      "10. **Montpellier**: With a vibrant student population and Mediterranean climate, Montpellier combines old and modern architecture in a lively setting.\n",
      "\n",
      "Each of these cities offers a unique glimpse into French culture and lifestyle.\n",
      "\u001b[1;31;32m\n",
      "Note: üö´ No Bing call search was made\n"
     ]
    }
   ],
   "source": [
    "# The main agent will use the bing search\n",
    "await main_agent(\"What are the top cities in France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Bing for Azure AI Agent Service\n",
      "\n",
      "1. Created agent, ID: asst_J5X99TKBrlHHLEL81ub23kRQ\n",
      "2. Created thread, ID: thread_REtYYAY0onmzsO94s9Tgasp2\n",
      "3. Message: {'id': 'msg_QZVfeTcmdyL4SNdevmThZBbX', 'object': 'thread.message', 'created_at': 1747828122, 'assistant_id': None, 'thread_id': 'thread_REtYYAY0onmzsO94s9Tgasp2', 'run_id': None, 'role': 'user', 'content': [{'type': 'text', 'text': {'value': 'current weather in Paris', 'annotations': []}}], 'attachments': [], 'metadata': {}}\n",
      "4. Run finished with status: completed\n",
      "\n",
      "Full response: source='bing_agent' models_usage=None metadata={} content='The current weather in Paris on May 21, 2025, is characterized by temperatures ranging from 11¬∞C to 21¬∞C. The skies are mostly cloudy with expected drizzle in the evening„Äê3:0‚Ä†source„Äë„Äê3:2‚Ä†source„Äë.' type='ToolCallSummaryMessage'\n",
      "\u001b[1;31;34m\n",
      "Answer: The current weather in Paris on May 21, 2025, is characterized by temperatures ranging from 11¬∞C to 21¬∞C. The skies are mostly cloudy with expected drizzle in the evening„Äê3:0‚Ä†source„Äë„Äê3:2‚Ä†source„Äë.\n",
      "\u001b[1;31;32m\n",
      "Note: üîç A Bing call search was made\n"
     ]
    }
   ],
   "source": [
    "# The main agent will use the bing search\n",
    "await main_agent(\"What is the weather for Paris?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Bing for Azure AI Agent Service\n",
      "\n",
      "1. Created agent, ID: asst_xhaf1EWFbA1tf4DEsn2uNrF4\n",
      "2. Created thread, ID: thread_sWjy3JnDrnYZFo8V95iNFHjL\n",
      "3. Message: {'id': 'msg_ZouXv6kuIEQ0Rk4ayNY04BvG', 'object': 'thread.message', 'created_at': 1747828133, 'assistant_id': None, 'thread_id': 'thread_sWjy3JnDrnYZFo8V95iNFHjL', 'run_id': None, 'role': 'user', 'content': [{'type': 'text', 'text': {'value': 'current Prime Minister of France', 'annotations': []}}], 'attachments': [], 'metadata': {}}\n",
      "4. Run finished with status: completed\n",
      "\n",
      "Full response: source='bing_agent' models_usage=None metadata={} content='The current Prime Minister of France is Fran√ßois Bayrou. He was appointed to this position in December 2024„Äê3:9‚Ä†source„Äë.' type='ToolCallSummaryMessage'\n",
      "\u001b[1;31;34m\n",
      "Answer: The current Prime Minister of France is Fran√ßois Bayrou. He was appointed to this position in December 2024„Äê3:9‚Ä†source„Äë.\n",
      "\u001b[1;31;32m\n",
      "Note: üîç A Bing call search was made\n"
     ]
    }
   ],
   "source": [
    "# The main agent will use the bing search\n",
    "await main_agent(\"Who is the prime minister of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
