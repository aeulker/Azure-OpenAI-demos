{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "431cc026-279f-4105-8444-f1b93650da0d",
   "metadata": {},
   "source": [
    "# Azure AI Agents - File Search\n",
    "\n",
    "<img src=\"https://learn.microsoft.com/en-us/azure/ai-services/agents/media/agent-service-the-glue.png\" width=800>\n",
    "\n",
    "> https://learn.microsoft.com/en-us/azure/ai-services/agents/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a3e72d0-7521-438c-928d-5fa293b0f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from azure.ai.agents import AgentsClient\n",
    "from azure.ai.agents.models import (\n",
    "    FileSearchTool,\n",
    "    FilePurpose,\n",
    "    ListSortOrder, MessageAttachment\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65334de7-4005-401a-89c1-be24f75abbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"azure.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8628712a-0d10-4351-8993-b4c3243f83be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2c1d28-e366-442e-a186-81239ec337ec",
   "metadata": {},
   "source": [
    "## Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76c7bbb7-0faa-4500-ba42-7c5b176f6196",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = os.getenv(\"PROJECT_ENDPOINT\")\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "project_client = AgentsClient(endpoint=endpoint, credential=credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad783cf5-ab5a-4bdb-9536-0611a7846eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "output_file = os.path.join(DATA_DIR, \"document.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ca097a7-2788-46c3-b49d-b8e8fe75d9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-06-10 09:11:01--  https://arxiv.org/abs/2311.06242\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.3.42, 151.101.67.42, 151.101.131.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.3.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 48005 (47K) [text/html]\n",
      "Saving to: ‘data/document.pdf’\n",
      "\n",
      "data/document.pdf   100%[===================>]  46.88K  --.-KB/s    in 0.002s  \n",
      "\n",
      "2025-06-10 09:11:01 (30.0 MB/s) - ‘data/document.pdf’ saved [48005/48005]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://arxiv.org/abs/2311.06242 -O $output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6cabed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe1a5582-f733-4775-9225-42f6e909e810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file, file ID: assistant-4wqVjrjAbM8KaxrYdQVKkn\n",
      "Created vector store, vector store ID: vs_ofyHrvAfygkSFZYhyYh43jHH\n"
     ]
    }
   ],
   "source": [
    "file = project_client.files.upload_and_poll(file_path=output_file,\n",
    "                                                  purpose=FilePurpose.AGENTS)\n",
    "\n",
    "print(f\"Uploaded file, file ID: {file.id}\")\n",
    "\n",
    "# create a vector store with the file you uploaded\n",
    "vector_store = project_client.vector_stores.create_and_poll(\n",
    "    file_ids=[file.id], name=\"document_vector_store\")\n",
    "\n",
    "print(f\"Created vector store, vector store ID: {vector_store.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f45913d3-1182-4a04-90c4-a2557909d315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, agent ID: asst_8joTpOGQE80pao21DZIgzXPE\n"
     ]
    }
   ],
   "source": [
    "# create a file search tool\n",
    "file_search_tool = FileSearchTool(vector_store_ids=[vector_store.id])\n",
    "\n",
    "# notices that FileSearchTool as tool and tool_resources must be added or the agent will be unable to search the file\n",
    "agent = project_client.create_agent(\n",
    "    model=model,\n",
    "    name=\"document_agent\",\n",
    "    instructions=\"You are an AI helpful agent to analyse document\",\n",
    "    tools=file_search_tool.definitions,\n",
    "    tool_resources=file_search_tool.resources,\n",
    "    description=\"Document Agent\",\n",
    ")\n",
    "\n",
    "print(f\"Created agent, agent ID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5c6bc41-e39f-4905-8602-4c23fe0febce",
   "metadata": {},
   "outputs": [],
   "source": [
    "id1 = agent.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c8a3595-7db7-4047-8745-d2bb25c63e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread, thread ID: thread_0uCqRY2EHWjLn5RJJgPsz5aD\n",
      "Uploaded file, file ID: assistant-WwPQyftXKpxWh5wvx6NGZZ\n",
      "Created message, message ID: msg_TpxHUQsrSZgT6kFFJZ7eOMyo\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "thread = project_client.threads.create()\n",
    "print(f\"Created thread, thread ID: {thread.id}\")\n",
    "\n",
    "# Upload the user provided file as a messsage attachment\n",
    "message_file = project_client.files.upload_and_poll(\n",
    "    file_path=output_file, purpose=FilePurpose.AGENTS)\n",
    "\n",
    "print(f\"Uploaded file, file ID: {message_file.id}\")\n",
    "\n",
    "# Create a message with the file search attachment\n",
    "# Notice that vector store is created temporarily when using attachments with a default expiration policy of seven days.\n",
    "attachment = MessageAttachment(file_id=message_file.id,\n",
    "                               tools=FileSearchTool().definitions)\n",
    "\n",
    "prompt = \"Summarize this document in three lines.\"\n",
    "\n",
    "message = project_client.messages.create(thread_id=thread.id,\n",
    "                                               role=\"user\",\n",
    "                                               content=prompt,\n",
    "                                               attachments=[attachment])\n",
    "\n",
    "print(f\"Created message, message ID: {message.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54f6f557-18fb-41c4-8cee-eb3d0300d158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created run, run ID: run_yc6KjmRXSW3sxwWnpcdN1QfQ\n",
      "Messages: <iterator object azure.core.paging.ItemPaged at 0x7ff1fc4b3bb0>\n"
     ]
    }
   ],
   "source": [
    "run = project_client.runs.create_and_process(thread_id=thread.id,\n",
    "                                                   agent_id=agent.id)\n",
    "print(f\"Created run, run ID: {run.id}\")\n",
    "\n",
    "messages = project_client.messages.list(thread_id=thread.id)\n",
    "print(f\"Messages: {messages}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33d14e13-f3bd-4822-a679-0aa322bc98f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: Summarize this document in three lines.\n",
      "assistant: The document presents \"Florence-2,\" a novel vision foundation model designed for various computer vision and vision-language tasks. It utilizes a unified, prompt-based approach, enabling versatile task performance including captioning, object detection, and segmentation, backed by a large dataset consisting of 5.4 billion visual annotations. Evaluations indicate Florence-2's strong capabilities in both zero-shot and fine-tuning scenarios, marking it as a competitive player in the field【4:8†source】.\n"
     ]
    }
   ],
   "source": [
    "# Fetch and log all messages\n",
    "messages = project_client.messages.list(thread_id=thread.id, order=ListSortOrder.ASCENDING)\n",
    "\n",
    "# Print last messages from the thread\n",
    "for msg in messages:\n",
    "    if msg.text_messages:\n",
    "        last_text = msg.text_messages[-1]\n",
    "        print(f\"{msg.role}: {last_text.text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffac954d-32ff-4f13-bf06-f567d06b92b3",
   "metadata": {},
   "source": [
    "## Another question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "652a3050-4486-40c9-94e7-a7ee8532ebdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created message, message ID: msg_lg3oavm8JL9w3ur5TVYEUcnb\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Summarize this document.\"\n",
    "\n",
    "message = project_client.messages.create(thread_id=thread.id,\n",
    "                                               role=\"user\",\n",
    "                                               content=prompt,\n",
    "                                               attachments=[attachment])\n",
    "\n",
    "print(f\"Created message, message ID: {message.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a57d170e-d03e-4d05-8914-93b54b0846f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created run, run ID: run_012dh2hNXxBWhOhnU8ubOC4i\n",
      "Messages: <iterator object azure.core.paging.ItemPaged at 0x7ff1fc3e1120>\n"
     ]
    }
   ],
   "source": [
    "run = project_client.runs.create_and_process(thread_id=thread.id,\n",
    "                                                   agent_id=agent.id)\n",
    "print(f\"Created run, run ID: {run.id}\")\n",
    "\n",
    "messages = project_client.messages.list(thread_id=thread.id)\n",
    "print(f\"Messages: {messages}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3de78f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message ID: msg_zSpUH2b2W6WsLtIECvtSIMXn, Role: assistant, Content: [{'type': 'text', 'text': {'value': 'The document introduces \"Florence-2,\" a cutting-edge vision foundation model implemented with a unified, prompt-based representation facilitating diverse computer vision and vision-language tasks such as captioning, object detection, and segmentation. This model was trained on a vast dataset, FLD-5B, featuring 5.4 billion visual annotations derived from 126 million images, utilizing an iterative approach for data annotation. Extensive evaluations confirmed Florence-2\\'s efficacy, showcasing strong zero-shot and fine-tuning capabilities that position it as a formidable player in the field of computer vision【10:0†source】.', 'annotations': [{'type': 'file_citation', 'text': '【10:0†source】', 'start_index': 612, 'end_index': 625, 'file_citation': {'file_id': 'assistant-WwPQyftXKpxWh5wvx6NGZZ'}}]}}]\n",
      "Message ID: msg_lg3oavm8JL9w3ur5TVYEUcnb, Role: user, Content: [{'type': 'text', 'text': {'value': 'Summarize this document.', 'annotations': []}}]\n",
      "Message ID: msg_dvQQxCnUSiqm5e7o9o2Z4Gi1, Role: assistant, Content: [{'type': 'text', 'text': {'value': 'The document presents \"Florence-2,\" a novel vision foundation model designed for various computer vision and vision-language tasks. It utilizes a unified, prompt-based approach, enabling versatile task performance including captioning, object detection, and segmentation, backed by a large dataset consisting of 5.4 billion visual annotations. Evaluations indicate Florence-2\\'s strong capabilities in both zero-shot and fine-tuning scenarios, marking it as a competitive player in the field【4:8†source】.', 'annotations': [{'type': 'file_citation', 'text': '【4:8†source】', 'start_index': 490, 'end_index': 502, 'file_citation': {'file_id': 'assistant-WwPQyftXKpxWh5wvx6NGZZ'}}]}}]\n",
      "Message ID: msg_TpxHUQsrSZgT6kFFJZ7eOMyo, Role: user, Content: [{'type': 'text', 'text': {'value': 'Summarize this document in three lines.', 'annotations': []}}]\n"
     ]
    }
   ],
   "source": [
    "messages = project_client.messages.list(thread_id=thread.id)\n",
    "\n",
    "for message in messages:\n",
    "    print(f\"Message ID: {message.id}, Role: {message.role}, Content: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbd185b6-092a-4c67-900e-497d3b792af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: [{'type': 'text', 'text': {'value': 'The document introduces \"Florence-2,\" a cutting-edge vision foundation model implemented with a unified, prompt-based representation facilitating diverse computer vision and vision-language tasks such as captioning, object detection, and segmentation. This model was trained on a vast dataset, FLD-5B, featuring 5.4 billion visual annotations derived from 126 million images, utilizing an iterative approach for data annotation. Extensive evaluations confirmed Florence-2\\'s efficacy, showcasing strong zero-shot and fine-tuning capabilities that position it as a formidable player in the field of computer vision【10:0†source】.', 'annotations': [{'type': 'file_citation', 'text': '【10:0†source】', 'start_index': 612, 'end_index': 625, 'file_citation': {'file_id': 'assistant-WwPQyftXKpxWh5wvx6NGZZ'}}]}}]\n"
     ]
    }
   ],
   "source": [
    "messages = list(project_client.messages.list(thread_id=thread.id))\n",
    "\n",
    "if messages:\n",
    "    last_message = messages[0]\n",
    "    print(f\"Content: {last_message.content}\")\n",
    "else:\n",
    "    print(\"No messages found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b0a7b5e-e9de-4515-a762-9d2055099294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created message, message ID: msg_vQVNI66ZteD9rsDJkKrhxH2z\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Describe the Florence model.\"\n",
    "\n",
    "message = project_client.messages.create(thread_id=thread.id,\n",
    "                                               role=\"user\",\n",
    "                                               content=prompt,\n",
    "                                               attachments=[attachment])\n",
    "\n",
    "print(f\"Created message, message ID: {message.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d0335fd-019c-42dd-8eba-fdc38c881395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created run, run ID: run_crUeVdYfmNt0xJZhsGpBTkP8\n",
      "Messages: <iterator object azure.core.paging.ItemPaged at 0x7ff1fc309c60>\n"
     ]
    }
   ],
   "source": [
    "run = project_client.runs.create_and_process(thread_id=thread.id,\n",
    "                                                   agent_id=agent.id)\n",
    "print(f\"Created run, run ID: {run.id}\")\n",
    "\n",
    "messages = project_client.messages.list(thread_id=thread.id)\n",
    "print(f\"Messages: {messages}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9399de0-d756-480f-b90f-d54325874358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message ID: msg_x4dAIVN0TQvDHmTX2oa7ZuYb, Role: assistant, Content: [{'type': 'text', 'text': {'value': 'The Florence model, specifically Florence-2, is a novel vision foundation model that employs a unified, prompt-based representation designed to address a wide array of computer vision and vision-language tasks. It allows for versatile applications, such as captioning, object detection, grounding, and segmentation, by taking text prompts as instructions and generating outcomes in text format. Developed through a sequence-to-sequence framework, Florence-2 was trained on the comprehensive FLD-5B dataset, which includes 5.4 billion visual annotations, enabling it to exhibit exceptional zero-shot and fine-tuning capabilities, positioning it as a strong contender in the vision model landscape【13:1†source】【13:0†source】【13:10†source】.', 'annotations': [{'type': 'file_citation', 'text': '【13:1†source】', 'start_index': 695, 'end_index': 708, 'file_citation': {'file_id': 'assistant-4wqVjrjAbM8KaxrYdQVKkn'}}, {'type': 'file_citation', 'text': '【13:0†source】', 'start_index': 708, 'end_index': 721, 'file_citation': {'file_id': 'assistant-WwPQyftXKpxWh5wvx6NGZZ'}}, {'type': 'file_citation', 'text': '【13:10†source】', 'start_index': 721, 'end_index': 735, 'file_citation': {'file_id': 'assistant-WwPQyftXKpxWh5wvx6NGZZ'}}]}}]\n",
      "Message ID: msg_vQVNI66ZteD9rsDJkKrhxH2z, Role: user, Content: [{'type': 'text', 'text': {'value': 'Describe the Florence model.', 'annotations': []}}]\n",
      "Message ID: msg_zSpUH2b2W6WsLtIECvtSIMXn, Role: assistant, Content: [{'type': 'text', 'text': {'value': 'The document introduces \"Florence-2,\" a cutting-edge vision foundation model implemented with a unified, prompt-based representation facilitating diverse computer vision and vision-language tasks such as captioning, object detection, and segmentation. This model was trained on a vast dataset, FLD-5B, featuring 5.4 billion visual annotations derived from 126 million images, utilizing an iterative approach for data annotation. Extensive evaluations confirmed Florence-2\\'s efficacy, showcasing strong zero-shot and fine-tuning capabilities that position it as a formidable player in the field of computer vision【10:0†source】.', 'annotations': [{'type': 'file_citation', 'text': '【10:0†source】', 'start_index': 612, 'end_index': 625, 'file_citation': {'file_id': 'assistant-WwPQyftXKpxWh5wvx6NGZZ'}}]}}]\n",
      "Message ID: msg_lg3oavm8JL9w3ur5TVYEUcnb, Role: user, Content: [{'type': 'text', 'text': {'value': 'Summarize this document.', 'annotations': []}}]\n",
      "Message ID: msg_dvQQxCnUSiqm5e7o9o2Z4Gi1, Role: assistant, Content: [{'type': 'text', 'text': {'value': 'The document presents \"Florence-2,\" a novel vision foundation model designed for various computer vision and vision-language tasks. It utilizes a unified, prompt-based approach, enabling versatile task performance including captioning, object detection, and segmentation, backed by a large dataset consisting of 5.4 billion visual annotations. Evaluations indicate Florence-2\\'s strong capabilities in both zero-shot and fine-tuning scenarios, marking it as a competitive player in the field【4:8†source】.', 'annotations': [{'type': 'file_citation', 'text': '【4:8†source】', 'start_index': 490, 'end_index': 502, 'file_citation': {'file_id': 'assistant-WwPQyftXKpxWh5wvx6NGZZ'}}]}}]\n",
      "Message ID: msg_TpxHUQsrSZgT6kFFJZ7eOMyo, Role: user, Content: [{'type': 'text', 'text': {'value': 'Summarize this document in three lines.', 'annotations': []}}]\n"
     ]
    }
   ],
   "source": [
    "messages = project_client.messages.list(thread_id=thread.id)\n",
    "\n",
    "for message in messages:\n",
    "    print(f\"Message ID: {message.id}, Role: {message.role}, Content: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98e7c5c8-baad-4108-b021-e32107909551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: [{'type': 'text', 'text': {'value': 'The Florence model, specifically Florence-2, is a novel vision foundation model that employs a unified, prompt-based representation designed to address a wide array of computer vision and vision-language tasks. It allows for versatile applications, such as captioning, object detection, grounding, and segmentation, by taking text prompts as instructions and generating outcomes in text format. Developed through a sequence-to-sequence framework, Florence-2 was trained on the comprehensive FLD-5B dataset, which includes 5.4 billion visual annotations, enabling it to exhibit exceptional zero-shot and fine-tuning capabilities, positioning it as a strong contender in the vision model landscape【13:1†source】【13:0†source】【13:10†source】.', 'annotations': [{'type': 'file_citation', 'text': '【13:1†source】', 'start_index': 695, 'end_index': 708, 'file_citation': {'file_id': 'assistant-4wqVjrjAbM8KaxrYdQVKkn'}}, {'type': 'file_citation', 'text': '【13:0†source】', 'start_index': 708, 'end_index': 721, 'file_citation': {'file_id': 'assistant-WwPQyftXKpxWh5wvx6NGZZ'}}, {'type': 'file_citation', 'text': '【13:10†source】', 'start_index': 721, 'end_index': 735, 'file_citation': {'file_id': 'assistant-WwPQyftXKpxWh5wvx6NGZZ'}}]}}]\n"
     ]
    }
   ],
   "source": [
    "messages = list(project_client.messages.list(thread_id=thread.id))\n",
    "\n",
    "if messages:\n",
    "    last_message = messages[0]\n",
    "    print(f\"Content: {last_message.content}\")\n",
    "else:\n",
    "    print(\"No messages found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4297511-c6e7-4f36-901a-a82335603f9b",
   "metadata": {},
   "source": [
    "## Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb0c38dd-e8c0-47f8-a4a1-60edcdd30f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing all agents in the project:\n",
      "Agent ID: asst_8joTpOGQE80pao21DZIgzXPE, Name: document_agent, Model: gpt-4o-mini, Instructions: You are an AI helpful agent to analyse document\n"
     ]
    }
   ],
   "source": [
    "# List all agents in the project\n",
    "print(\"Listing all agents in the project:\")\n",
    "\n",
    "agents = project_client.list_agents()\n",
    "for agent in agents:\n",
    "    print(f\"Agent ID: {agent.id}, Name: {agent.name}, Model: {agent.model}, Instructions: {agent.instructions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a286c728-6904-4c2e-9a02-61871f66c578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted agent, agent ID: asst_8joTpOGQE80pao21DZIgzXPE\n"
     ]
    }
   ],
   "source": [
    "project_client.delete_agent(id1)\n",
    "print(f\"Deleted agent, agent ID: {id1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8aa506-186b-4592-91ee-c0a0dc7a288a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
