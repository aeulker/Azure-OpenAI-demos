{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d80035c0-22bb-4d6e-bfb0-7a6391bbe8a8",
   "metadata": {},
   "source": [
    "# Responses API - chat on your own image\n",
    "\n",
    "The Responses API provides a structured response format that allows AI to interact with multiple tools while maintaining context across interactions. It supports: \n",
    "\n",
    "- Tool calling in one simple API call: Now, developers can seamlessly integrate AI tools, making execution more efficient. \n",
    "- Computer use: Use the computer use tool within the Responses API to drive automation and execute software interactions. \n",
    "- File search: Interact with enterprise data dynamically and extract relevant information. \n",
    "- Function calling: Develop and invoke custom functions to enhance AI capabilities. \n",
    "- Chaining responses into conversations: Keep track of interactions by linking responses together using unique response IDs, ensuring continuity in AI-driven dialogues. \n",
    "- Enterprise-grade data privacy: Built with Azureâ€™s trusted security and compliance standards, ensuring data protection for organizations\n",
    "  \n",
    "> https://azure.microsoft.com/en-us/blog/announcing-the-responses-api-and-computer-using-agent-in-azure-ai-foundry/?msockid=2e39c66c693c66a5151fd200687567d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63186607-e61b-45e2-8729-95d380fc2ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import gradio as gr\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from openai import AzureOpenAI, OpenAI\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "911225de-5af9-4690-95a6-4edcd29998fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "714fc24d-81da-4c74-8f3d-0fff479c82e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 18-Apr-2025 07:30:26\n"
     ]
    }
   ],
   "source": [
    "print(f\"Today is {datetime.today().strftime('%d-%b-%Y %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cb693e6-f972-4686-a61e-02d5fcb28f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"azure.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9b1f688-9d35-44e1-979c-e4a5583bbaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client():\n",
    "    \"\"\"\n",
    "    Retrieves the deployment name and initializes the Azure OpenAI client.\n",
    "\n",
    "    This function fetches the necessary configuration details from environment variables\n",
    "    and creates an instance of the AzureOpenAI client.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the deployment name (str) and the AzureOpenAI client instance.\n",
    "    \"\"\"\n",
    "    deployment = os.environ[\"AZURE_OPENAI_API_MODEL\"]\n",
    "    \n",
    "    client = AzureOpenAI(\n",
    "        api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "        api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "        azure_endpoint=os.environ[\"AZURE_OPENAI_API_ENDPOINT\"])\n",
    "\n",
    "    return deployment, client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39754700-f266-46b3-b9ae-f17f59bb88b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment, client = get_client()\n",
    "\n",
    "previous_response_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a18dc412-257c-46f2-9323-157f7e2b28cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    \"\"\"\n",
    "    Encodes an image file to a base64 string.\n",
    "\n",
    "    This function reads an image file from the specified path, encodes its content\n",
    "    to base64, and returns the encoded string.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The path to the image file to be encoded.\n",
    "\n",
    "    Returns:\n",
    "        str: The base64 encoded string of the image content.\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79002255-296c-4d85-80a2-8c61010128b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_stream(user_prompt, history, file_path):\n",
    "    \"\"\"\n",
    "    Manages a streaming conversation with the Azure OpenAI client.\n",
    "\n",
    "    This function initializes the conversation history, processes the user prompt,\n",
    "    and handles streaming responses from the Azure OpenAI client. It supports\n",
    "    image uploads by encoding them to base64 and including them in the input payload.\n",
    "\n",
    "    Args:\n",
    "        user_prompt (str): The user's input prompt for the conversation.\n",
    "        history (list): The conversation history, which is a list of message dictionaries.\n",
    "        file_path (str): The path to an image file to be included in the conversation, if any.\n",
    "\n",
    "    Yields:\n",
    "        tuple: A tuple containing the updated conversation history twice, to update the UI.\n",
    "\n",
    "    Environment Variables:\n",
    "        deployment (str): The deployment name for the Azure OpenAI model.\n",
    "        client (AzureOpenAI): The Azure OpenAI client instance.\n",
    "        previous_response_id (str): The ID of the previous response for context.\n",
    "    \"\"\"\n",
    "    # Ensure the history list is initialized\n",
    "    if history is None:\n",
    "        history = []\n",
    "\n",
    "    # Add the user prompt to the conversation history with appropriate role\n",
    "    history.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "    # Create and add a placeholder for the assistant's reply\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    history.append(assistant_message)\n",
    "\n",
    "    # Yield initial state to update the UI\n",
    "    yield history, history\n",
    "\n",
    "    # Prepare parameters for the API call, including model name and streaming flag\n",
    "    global previous_response_id\n",
    "    params = {\n",
    "        \"model\": deployment,\n",
    "        \"input\": [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt\n",
    "        }],\n",
    "        \"stream\": True\n",
    "    }\n",
    "\n",
    "    # Attach the previous response ID for context if available\n",
    "    if previous_response_id:\n",
    "        params[\"previous_response_id\"] = previous_response_id\n",
    "\n",
    "    # If an image file was uploaded, encode it to base64 and add it to the input payload\n",
    "    if file_path is not None:\n",
    "        base64_image = encode_image(file_path)\n",
    "        params[\"input\"].append({\n",
    "            \"role\":\n",
    "            \"user\",\n",
    "            \"content\": [{\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": f\"data:image/png;base64,{base64_image}\"\n",
    "            }]\n",
    "        })\n",
    "\n",
    "    # Initiate the streaming conversation using the client\n",
    "    stream = client.responses.create(**params)\n",
    "\n",
    "    # Process each event from the stream to build the complete assistant message\n",
    "    for event in stream:\n",
    "        # Record the response id from the first event\n",
    "        if event.type == 'response.created':\n",
    "            previous_response_id = event.response.id\n",
    "\n",
    "        # Append new text received in the stream to the assistant message\n",
    "        if event.type == 'response.output_text.delta':\n",
    "            assistant_message[\"content\"] += event.delta\n",
    "            yield history, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb4de521-2b5c-4974-97a7-8d479706fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_chat():\n",
    "    \"\"\"\n",
    "    Clears the conversation history and resets the previous response ID.\n",
    "\n",
    "    This function resets the global `previous_response_id` to `None` and returns\n",
    "    empty lists for the conversation history and assistant messages, along with `None`\n",
    "    for the file path.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing three elements:\n",
    "            - An empty list for the user message history.\n",
    "            - An empty list for the assistant message history.\n",
    "            - None for the file path.\n",
    "    \"\"\"\n",
    "    global previous_response_id\n",
    "\n",
    "    previous_response_id = None\n",
    "    return [], [], None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a9541b1-569a-4be0-8701-9d35f8d56bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_textbox():\n",
    "    \"\"\"\n",
    "    Clears the content of a textbox.\n",
    "\n",
    "    This function returns an empty string, effectively clearing any text\n",
    "    that might be present in a textbox.\n",
    "\n",
    "    Returns:\n",
    "        str: An empty string.\n",
    "    \"\"\"\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adde222e-f6a2-4085-a4c7-6e9c6200ca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Gradio Blocks interface for the chat demo\n",
    "with gr.Blocks() as webapp:\n",
    "    # Header Markdown text for the demo UI, centered\n",
    "    gr.Markdown(\n",
    "        \"<h2 style='text-align: center;'>Chat with your image</h2>\"\n",
    "    )\n",
    "    # Chatbot component to display messages stored in a list of role-content dictionaries\n",
    "    chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "    # State to maintain the conversation history between messages\n",
    "    state = gr.State([])\n",
    "    # Textbox for user input with a placeholder message\n",
    "    msg = gr.Textbox(show_label=False,\n",
    "                     placeholder=\"ðŸš€ Your query and press Enter\")\n",
    "    # Row containing the Submit and Clear buttons\n",
    "    with gr.Row():\n",
    "        submit_btn = gr.Button(\"ðŸ”¥Submit\")\n",
    "        clear_btn = gr.Button(\"Clear\")\n",
    "    # File upload control for image inputs (placed below the buttons)\n",
    "    file_picker = gr.File(label=\"âœ… Upload an image file\",\n",
    "                          file_count=\"single\",\n",
    "                          type=\"filepath\",\n",
    "                          file_types=[\".jpg\", \".jpeg\", \".png\"],\n",
    "                          height=140)\n",
    "    # Bind the Textbox submit action to the stream processing function and clear the textbox after submission\n",
    "    msg.submit(fn=chat_stream,\n",
    "               inputs=[msg, state, file_picker],\n",
    "               outputs=[chatbot, state]).then(clear_textbox, None, msg)\n",
    "    # Also bind the submit button to the same functionality as the Textbox submit\n",
    "    submit_btn.click(fn=chat_stream,\n",
    "                     inputs=[msg, state, file_picker],\n",
    "                     outputs=[chatbot, state]).then(clear_textbox, None, msg)\n",
    "    # Bind the clear button to reset the chat and clear the file upload\n",
    "    clear_btn.click(fn=clear_chat,\n",
    "                    inputs=[],\n",
    "                    outputs=[chatbot, state, file_picker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0beaaa2-e77f-430b-bf14-e6c0f5c8eae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://0708cbd3f465a768c0.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://0708cbd3f465a768c0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webapp.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac9a11a-5649-4c54-9135-0a085d2d3f78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
